{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2b_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYxruKGDdyoe"
      },
      "source": [
        "## Another Classification exercise\r\n",
        "\r\n",
        "We will use the \"Social_Network_Ads\" dataset for this exercise. \r\n",
        "The dataset is on social network ads and users' click-through. \r\n",
        "\r\n",
        "We want to build a model to predict if a new user will click on an ad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ2efaGgr-Jc"
      },
      "source": [
        "##Data preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTUWSdq0r0oL"
      },
      "source": [
        "# make sure to upload the dataset to your colab folder before proceeding (see instructions in \"Getting Started with Colab\")\n",
        "#loading the 50_startups datasets as a panda dataframe\n",
        "import pandas as pd\n",
        "df = pd.read_csv('Social_Network_Ads.csv')\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKXJt52-U37p"
      },
      "source": [
        "# number of users who Clicked on the ad\n",
        "df['Clicked'].sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJbxE_Y-U2cF"
      },
      "source": [
        "#visually explore the data: correlation matrix of the dataset\n",
        "import seaborn as sb\n",
        "cormatrix=df.corr()\n",
        "sb.heatmap(cormatrix,cmap='YlGn') \n",
        "#cmap(colormap) options: 'Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds','YlOrBr', 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu','GnBu', 'PuBu', 'YlGnBu', 'PuBuGn', 'BuGn', 'YlGn'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj4zNLQ7alf7"
      },
      "source": [
        "##preparing the data for model training\n",
        "y = df[['Clicked']]  \n",
        "X = df[['Age','EstimatedSalary']] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg9BVLAkmako"
      },
      "source": [
        "None of the potential predictor/input/X variables are categorical, so we won't need to encode them (i.e., dummy or OneHot encoding). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aVVXrE4a6cC"
      },
      "source": [
        "X.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gCUNlYxJ2Bm"
      },
      "source": [
        "y.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsdhKN9LYZdX"
      },
      "source": [
        "## Splitting the data into Train/Test set\n",
        "We will split the data intro train and test set, try several classifications models, and evaluate their predicitve performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4QzSrPCggF8"
      },
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VfCF42abPBb"
      },
      "source": [
        "#splitting the dataset into training (70%) and testing (30%)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 123)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUJDL1X9baLe"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "#uncomment ONLY one the following two, depending on how you want to scale the data\n",
        "#sc = StandardScaler() #standardization\n",
        "sc = MinMaxScaler() #minmax scaling\n",
        "X_train_sc=sc.fit_transform(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcCDfWjqK97X"
      },
      "source": [
        "# Let's compare the histograms of pre/post scaling for one variable (\"mean radius\") in our training data (X_train)\n",
        "import matplotlib.pyplot as plt\n",
        "fig, axs = plt.subplots(ncols=2)\n",
        "sb.distplot(X_train[X_train.columns[1]], ax=axs[0])\n",
        "sb.distplot(X_train_sc[[1]], ax=axs[1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiw5IBzbbaPJ"
      },
      "source": [
        "##Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKQZPcaVMaIg"
      },
      "source": [
        "#using logistic regression \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic1 = LogisticRegression(random_state = 0, solver='liblinear')\n",
        "logistic1.fit(X_train_sc, y_train) #fitting the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBOmj75DRCvP"
      },
      "source": [
        "#using the trained model to predict outcome values for the test data (X_test)\n",
        "y_pred = logistic1.predict(sc.transform(X_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSFt8bXUbBfq"
      },
      "source": [
        "##Model Evaluation\n",
        "we can use sklearn.metrics to calculate performance metrics (the code is provided by commented out).\n",
        "\n",
        "Another option is scikitplot (which runs on top of sklearn) to create more appealing display for evaluation metrics such as the confusion matrix and various model evaluation plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Atk6LtyngvSP"
      },
      "source": [
        "!pip install scikit-plot #run once to install library"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1ceU2JBaoFI"
      },
      "source": [
        "#!pip install scikit-plot #run once to install library\n",
        "#using scikit plot for model evaluation\n",
        "import scikitplot as skplt\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred) #confusion matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq0DWYbioT6X"
      },
      "source": [
        "#Let's take a look at model's Precision, Recall, and Accuracy\n",
        "(metrics.precision_score(y_test, y_pred), #Precision\n",
        "metrics.recall_score(y_test, y_pred), #Recall\n",
        "metrics.accuracy_score(y_test, y_pred), #Accuracy\n",
        "metrics.balanced_accuracy_score(y_test, y_pred)) #Balanced Accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkEgTKX7eAHN"
      },
      "source": [
        "#calculate probabilty of each observation in X-test to belong to either outcome class; Benign=0 , Malignant=1\n",
        "y_pred_prob=logistic1.predict_proba(sc.fit_transform(X_test))\n",
        "#y_pred_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P85SppQ9esNt"
      },
      "source": [
        "#plotting the ROC curve to evalute the model's aggregate performance\n",
        "skplt.metrics.plot_roc_curve(y_test,y_pred_prob)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3IuCrWIg1nO"
      },
      "source": [
        "# plotting the precision-recall curve\r\n",
        "skplt.metrics.plot_precision_recall_curve(y_test,y_pred_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AWI0ngsvdNl"
      },
      "source": [
        "##Decision Tree Classification \n",
        "\n",
        "Learn more at https://scikit-learn.org/stable/modules/tree.html#tree "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8beH_jivn_e"
      },
      "source": [
        "#using the Decision Tree Classifier from sklearn\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "DecTree1 = DecisionTreeClassifier(criterion = 'entropy', random_state = 123) #change metric to 'gini' and rerun\n",
        "DecTree1.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAUVay9iv-Se"
      },
      "source": [
        "#using the model to predict outcomes for X_test\n",
        "y_pred = DecTree1.predict(X_test) \n",
        "#confusion matrix for the DecTree Classifier\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred)\n",
        "#calculating other model evalution metrics\n",
        "(metrics.precision_score(y_test, y_pred), #Precision\n",
        "metrics.recall_score(y_test, y_pred), #Recall\n",
        "metrics.accuracy_score(y_test, y_pred)) #Accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5axHJKle1OPV"
      },
      "source": [
        "Change the split criterion for the Decision Tree to 'gini' and rerun the model and evalution. \n",
        "###Question\n",
        "Does it improve the model? which metric did you consider for your answer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC8LZtoE2CK0"
      },
      "source": [
        "## Cross validation \n",
        "Is an approach to evalute machine learning models. CV helps with **overfitting** in supervised learning. It is also use to for model selection (selecting the best performing model between several candidates).\n",
        "\n",
        "https://scikit-learn.org/stable/modules/cross_validation.html \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjQBGwHOqHxw"
      },
      "source": [
        "##Comparing several models (using CV for model validation)\n",
        "Now we will put everything together and compare several models based on several performance metrics. We use k-fold cross-validation to evaluate each model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG7dlXqSrjZc"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# Compare Algorithms\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# prepare models\n",
        "models = []\n",
        "models.append(('LogisticReg', LogisticRegression(max_iter=500)))\n",
        "models.append(('K-NN      ', KNeighborsClassifier()))\n",
        "models.append(('DecisTree', DecisionTreeClassifier(criterion = 'entropy')))\n",
        "models.append(('NaiveBayes', GaussianNB()))\n",
        "models.append(('SVM       ', SVC())) # add a SVM classifieer\n",
        "# the next line adds a RandomForest classifier\n",
        "models.append(('RandForest', RandomForestClassifier(n_estimators = 10,criterion = 'entropy')))\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'precision' #metric we want to compare\n",
        "#see https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter for complete list of options\n",
        "for name, model in models:\n",
        "\tkfold = model_selection.KFold(n_splits=10, random_state=123)\n",
        "\tcv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "\tprint(msg)\n",
        "# boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison: ' +scoring)\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmR3qO9Chz9L"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF6c3nKDuxld"
      },
      "source": [
        "### Question\r\n",
        "Which model has the best Accuracy? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOIHJpifu0Kl"
      },
      "source": [
        "change the scoring metric in the previous code cell as needed to answer the following questions. For example: \r\n",
        "* scoring='accuracy'\r\n",
        "* scoring='precision'\r\n",
        "* scoring='recall'\r\n",
        "\r\n",
        "see https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter for a comprehensive list\r\n",
        "\r\n",
        "\r\n",
        "### Question \r\n",
        "Which model has the best Precision? best Recall?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UewLJf81BZW"
      },
      "source": [
        "## Interactive Visualization of Decision Tree Classifers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh87Dt8rixX3"
      },
      "source": [
        "!pip install ipywidgets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bgj72xZqy1kS"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn import tree\n",
        "from IPython.display import SVG\n",
        "from graphviz import Source\n",
        "from IPython.display import display                               \n",
        "from ipywidgets import interactive\n",
        "# class labels\n",
        "labels = X.columns #\n",
        "def plot_tree(crit, split, depth, min_split, min_leaf=0.2):\n",
        "  estimator = DecisionTreeClassifier(random_state = 0, criterion = crit, \n",
        "                                     splitter = split, max_depth = depth,\n",
        "                                     min_samples_split=min_split, \n",
        "                                     min_samples_leaf=min_leaf)\n",
        "  estimator.fit(X, y)\n",
        "  graph = Source(tree.export_graphviz(estimator, out_file=None, \n",
        "                                      feature_names=labels, \n",
        "                                      class_names=['0', '1', '2'], filled = True))\n",
        "  display(SVG(graph.pipe(format='svg')))\n",
        "  return estimator\n",
        "\n",
        "inter=interactive(plot_tree, \n",
        "                  crit = [\"gini\", \"entropy\"] , \n",
        "                  split = [\"best\", \"random\"] , \n",
        "                  depth=[1,2,3,4], \n",
        "                  min_split=(0.1,1), #min number of samples to further split a node\n",
        "                  min_leaf=(0.1,0.5)) #min number of samples required to be a leaf node\n",
        "display(inter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WevIkFtxi2Ox"
      },
      "source": [
        "###Question\r\n",
        "What is the most important variable to consider to predict whether a used will click on the ad?"
      ]
    }
  ]
}