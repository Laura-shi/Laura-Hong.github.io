{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "14_TopicModeling with BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_2ehW7x19jL"
      },
      "source": [
        "# Topic Modeling using BERT\n",
        "In this activity we will use BERTopic, which is a topic modeling technique that leverages BERT embeddings and a class-based TF-IDF to create dense clusters allowing for easily interpretable topics whilst keeping important words in the topic descriptions.\n",
        "\n",
        "For more details on BERTopic, see:\n",
        "https://maartengr.github.io/BERTopic/index.html \n",
        "\n",
        "https://github.com/MaartenGr/BERTopic "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUYInIoDLPu9"
      },
      "source": [
        "You can compare the resulting topics from this activity with topics we derived in our earlier activity using LDA for topic modeling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkJhljGq3IIt"
      },
      "source": [
        "#run once!\n",
        "!pip install bertopic \n",
        "!pip install bertopic[visualization]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAQp2_ZLBGJ4"
      },
      "source": [
        "## Data & Scenario\n",
        "\n",
        "We will use the same dataset on restaurant reviews we used for the earlier activity using LDA for topic modeling so that you can compare the results.  \n",
        "\n",
        "As explained earlier, we can explore whether there are certain topics that people write about in their reviews. These topics can be used to come up with different strategies to engage users on online platforms or other channels.  \n",
        "\n",
        "This is a small dataset for learning purposes and to avoid long processing times.\n",
        "You can use any other textual data as input. Depending on the data format, you may have to use different functions to import your text data. Once you have your data imported as a dataframe, where one colum contains the *documents*, the rest will be the same.\n",
        "\n",
        "Download the file \"**Restaurant_Reviews.tsv**\" form elearn and upload it to your session before processing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxdjezpdA-SX"
      },
      "source": [
        "# importing restaurant reviews dataset\n",
        "import pandas as pd\n",
        "df=pd.read_csv('Restaurant_Reviews.tsv',delimiter=\"\\t\")\n",
        "df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uhq7ywn2e3Jq"
      },
      "source": [
        "The sentiment for each review has been manually labeled for this dataset, we will not be using it for this activity; we only use the Review content. \n",
        "\n",
        "There are 996 unique reviews (documents, in NLP terminology)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bGsgQ7RBZJL"
      },
      "source": [
        "len(df)\n",
        "docs=df['Review']\n",
        "docs=docs.drop_duplicates() #drop duplicate reviews\n",
        "docs=docs.values\n",
        "len(docs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbll48z8M9Ky"
      },
      "source": [
        "#let's take a look at a document\n",
        "docs[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybVjVKYbNkb0"
      },
      "source": [
        "## Pre-processing\n",
        "Here we won't need to use the pre-processing steps as we did in our earlier activity, since the library we are using is going to automatically apply the needed text pre-processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6AEE0TBat6n"
      },
      "source": [
        "## Importing BERTopic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCHP5-5oMz18"
      },
      "source": [
        "#import BERTTopic\n",
        "from bertopic import BERTopic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRndHAyWN94a"
      },
      "source": [
        "This package is very easy to use, but there are several steps happening in the background (which are customizable, btw) and utilizes advanced pre-trained models (more on this later)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blxqeRMaS4eO"
      },
      "source": [
        "## Embeddings\n",
        "Let's recall our previous activities when we used RNNs for sentiment analysis and document classification. \n",
        "Remember those RNN models had an embedding layer (the first layer) that would convert tokens (words represented as integers) to vectors (word vectors); in sum, it would create word embeddings (vectors) from tokens so that similar words would be close in the resulting vector-space. \n",
        "\n",
        "Here, we have a similar process at the sentence-level (instead of token-level). The first step (happens in the background) is to create sentence embeddings using pre-trained models using what is known as \"sentence-transformers\"; sentence-transformers convert sentences into vector representations. These models are usually trained on very large collections of text (some for multilple languages) where the training goal is for the model to be able to predict some missing part of text (e.g., at the word or sentence level). This process can also be done at the document level, i.e., document embeddings.\n",
        "\n",
        "Here is a repository for pre-trained models https://huggingface.co/models. Depending on what sort of textual data you are working with (e.g., scientific articles, social media, etc.), you might want to use a library that is trained on type of text that is similar in nature to what you have. \n",
        "\n",
        "We will be using the default \"distilbert-base-nli-mean-tokens\" model (link to original paper https://arxiv.org/abs/1910.01108 ) for the english language. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6UMQb39M0Y9"
      },
      "source": [
        "# creating a instance of bertopic for \"english\", we are setting the parameters to save topic probablities (will use them later for visualization) \n",
        "model = BERTopic(language=\"english\",calculate_probabilities=True,verbose=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsoVXiU_Z1Jk"
      },
      "source": [
        "Notice that we are not specifying the number of topics here, contrary to when we do topic modeling using LDA.\n",
        "\n",
        "You could think of this as sth similar to what we had when we used DBSCAN for clustering where we don't specifiy number of clusters (vs. k-means where we had to specify the number of clusters)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c7lHmlGa1R2"
      },
      "source": [
        "## Running BERTopic on our corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRad0ojRNjR4"
      },
      "source": [
        "# apply the model on our documents and save both topics and probabilities (probability of each document belonging to any of the topics)\n",
        "topics, probabilities = model.fit_transform(docs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLyRo6lIbYay"
      },
      "source": [
        "## Derived Topics and their frequency\n",
        "\n",
        "Topic **-1** refers to all documents that did not have any topics assigned (outlier topic)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB-cehSXbWlH"
      },
      "source": [
        "# number of topics and freq (number of documents assigned to each topic)\n",
        "model.get_topic_freq().shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi1P6Q4obgNK"
      },
      "source": [
        "# Topic -1 refers to all documents that did not have any topics assigned (outlier topic).\n",
        "model.get_topic_freq()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xsow67b4g-U9"
      },
      "source": [
        "### Question 1\n",
        "How many topics were derived (aside from the outlier cluster)? \n",
        "\n",
        "... "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQW-npKKir1q"
      },
      "source": [
        "###Question 2\n",
        "How many documents are assigned to the first and second topic? \n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Ey8UVVc7dI"
      },
      "source": [
        "## Top words for a topic\n",
        "Let's take a look at top words that represent the first topic (topic=1), which has the most documents. You can simply change the topic number to look at the top words for other topics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuayPol-dLNn"
      },
      "source": [
        "# get top words for first topic\n",
        "model.get_topic(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQike7YDfci1"
      },
      "source": [
        "## Visualizing topics\n",
        "We can also visualize the derived topics (note that we installed the visualiazation library in the beginning of this notebook)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DepOaiXgdphm"
      },
      "source": [
        "model.visualize_topics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtYSFHGSeDVT"
      },
      "source": [
        "## Document-Topic probablities\n",
        "\n",
        "Each document in our corpus has a probability for belonging to each of the derived topics; we can derive these probabilities to use them for some other task (for example, as features for some predictive modeling task). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBbBLBqkdmrc"
      },
      "source": [
        "probabilities.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyni_aaBnndQ"
      },
      "source": [
        "# for example, we can export all these document-topic probabilities as a csv file. \n",
        "# pd.DataFrame(probabilities).to_csv(\"probs.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_8N39CEgKK9"
      },
      "source": [
        "## Visualize Topic probability distribution\n",
        "We can also visualize the Topic probability distribution for a specific document. \n",
        "Note that topics with a probablity beloew the specified threshold are not shown."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKod3YnZgekl"
      },
      "source": [
        "docs[4] # review number 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "974Tg3ccdrvb"
      },
      "source": [
        "# probablity of doc[4] (review 5) belonging to each of the topics\n",
        "model.visualize_distribution(probabilities[4],min_probability=0.005)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zodbK813gwwr"
      },
      "source": [
        "### Question 3\n",
        "Which topic does the 10th review belong to? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPYxBP0GPSEm"
      },
      "source": [
        "## What topic would a new review be most similar to?\n",
        "Let's see which topic(s) a new review would be more similar to.\n",
        "\n",
        "We have the option to derive similarity of a new piece of text to the derived topcis (in terms of cosine similarity between embeddings)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkMymGy3_p9l"
      },
      "source": [
        "new_review=\"The food was too salty but I liked the atmosphere.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPDBg5tRhswW"
      },
      "source": [
        "model.find_topics(new_review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG5mYkgLnNfx"
      },
      "source": [
        "###Question 4\n",
        "Which topic(s) is the new review most simlar to?\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9j2dx3jiO80"
      },
      "source": [
        "model.get_topic(15)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}