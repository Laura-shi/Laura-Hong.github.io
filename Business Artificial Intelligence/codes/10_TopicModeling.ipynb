{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_TopicModeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_2ehW7x19jL"
      },
      "source": [
        "# Topic Modeling \n",
        "\n",
        "In this activity we will use the Bag-of-Words (BOW) approach for text feature constructions, and LDA for topic modeling. \n",
        "We will use the gensim, nltk, and pyLDSvis libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkJhljGq3IIt"
      },
      "source": [
        "#run once!\n",
        "!pip install gensim==4.0.1\n",
        "!pip install pyldavis==3.3.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Smvq72OB3I5-"
      },
      "source": [
        "import gensim\n",
        "import pyLDAvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAQp2_ZLBGJ4"
      },
      "source": [
        "## Data & Scenario\n",
        "\n",
        "We will use a dataset on restaurant reviews for this exercise. We can explore whether there are certain topics that people write about in their reviews. These topics can be used to come pu with different strategies to engage with users on online platforms. \n",
        "\n",
        "This is a small dataset for learning purposes and to avoid long processing times.\n",
        "You can use any other textual data as input. Depending on the data format, you may have to use different functions to import your text data. Once you have your data imported as a dataframe, where one colum contains the *documents*, the rest will be the same.\n",
        "\n",
        "Download the file \"**Restaurant_Reviews.tsv**\" form elearn and upload it to your session before processing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxdjezpdA-SX"
      },
      "source": [
        "# importing restaurant reviews dataset\n",
        "import pandas as pd\n",
        "df=pd.read_csv('Restaurant_Reviews.tsv',delimiter=\"\\t\")\n",
        "df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uhq7ywn2e3Jq"
      },
      "source": [
        "The sentiment for each review has been manually labeled for this dataset, we will use it in another activity on sentimenet analysis. Here, we only use the Review content for the topic modeling. \n",
        "\n",
        "There are 1000 reviews. In NLP terminology, each Review is a ***document***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bGsgQ7RBZJL"
      },
      "source": [
        "len(df)\n",
        "docs=df['Review']\n",
        "docs=docs.drop_duplicates() #drop duplicate reviews\n",
        "docs=docs.values\n",
        "len(docs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNR0txA-jbop"
      },
      "source": [
        "##Text Pre-processing\n",
        "\n",
        "The pre-processing steps include:\n",
        "* tokenization: extracting the single words in each document\n",
        "* remove possible tags, e.g., characters from html documents \n",
        "* lowercase/uppercase all words (to not double count)\n",
        "* (optional) remove multiple whitespaces\n",
        "* remove punctuations \n",
        "* (optional) remove words that are shorter than 3 characters \n",
        "* remove stopwords; there are several stopword lists you can use, we use the default built-in from the gensim library\n",
        "* lemmatize words, using the NLTK implementation\n",
        "* stem words\n",
        "\n",
        "We will first apply each step on only one document (review) to see what exactly happens and then apply them on all documents. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dRQbwjuJepa"
      },
      "source": [
        "#installing and importing libraries we need\n",
        "import nltk\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "from gensim.parsing.preprocessing import strip_multiple_whitespaces,strip_numeric,strip_punctuation,strip_tags,strip_short,remove_stopwords,stem_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkz_aWeTt66A"
      },
      "source": [
        "#Let take a look at 1 review\n",
        "docs[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB1T86V1uLA-"
      },
      "source": [
        "tmp=strip_tags(docs[3]) #removing any tags (such as from html input) \n",
        "#changing all words to lower case, since we do not want to double count words \n",
        "tmp=tmp.lower() \n",
        "tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df0e6qHqusJw"
      },
      "source": [
        "tmp=strip_multiple_whitespaces(tmp) #remove consequent whitespaces\n",
        "tmp=strip_punctuation(tmp) #remove punctuations\n",
        "tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd5XGNExvLIr"
      },
      "source": [
        "#remove words that are shorter than 3 characters\n",
        "tmp=strip_short(tmp, minsize=3)\n",
        "tmp=remove_stopwords(tmp) #remove stopwords: is, the, as, etc.\n",
        "tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD_p8ngyvlL3"
      },
      "source": [
        "tmp=WordNetLemmatizer().lemmatize(tmp) #lemmatize words\n",
        "tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdffQhxywZFp"
      },
      "source": [
        "#stem words\n",
        "tmp=stem_text(tmp)\n",
        "tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38j98vdIdn--"
      },
      "source": [
        "#list the tokens \n",
        "list(gensim.utils.tokenize(tmp,deacc=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNrcF9kNj456"
      },
      "source": [
        "# If you want to apply all the above pre-processing steps you can also use the following function in the gensim library\n",
        "# For selective pre-processing steps (or just to know how exactly you are processing text) use the above approach\n",
        "gensim.parsing.preprocessing.preprocess_string(docs[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIRLu9X6zigN"
      },
      "source": [
        "## Applying pre-processing steps on corpus\n",
        "Now we will apply these steps except for stemming on our all documents (i.e., collection of all documents) and save it as a 2D list, \"text_data1\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK6O5nt8OfLx"
      },
      "source": [
        "text_data1 = []\n",
        "for eachdoc in docs:\n",
        "  tmp=strip_tags(eachdoc)\n",
        "  tmp=tmp.lower()\n",
        "  tmp=strip_multiple_whitespaces(tmp)\n",
        "  tmp=strip_punctuation(tmp)\n",
        "  tmp=strip_short(tmp)\n",
        "  tmp=remove_stopwords(tmp)\n",
        "  tmp=WordNetLemmatizer().lemmatize(tmp)\n",
        "  #tmp=stem_text(tmp)\n",
        "  text_data1.append(list(gensim.utils.tokenize(tmp,deacc=True)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCjezerqWFqp"
      },
      "source": [
        "# To apply all pre-processing steps you can also use the following function in gensim \n",
        "# strip_tags(),strip_punctuation(),strip_multiple_whitespaces(),strip_numeric(),remove_stopwords(),strip_short(),stem_text()\n",
        "text_data2=gensim.parsing.preprocessing.preprocess_documents(docs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9Ma4F4x4Dih"
      },
      "source": [
        "* text_data1, tokenization with pre-processing steps without stemming\n",
        "* text_data2, tokenization with all pre-processing steps \n",
        "\n",
        "both have equal length but the number of words for some documents may differ. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTwsIvBqWQNV"
      },
      "source": [
        "len(text_data1),len(text_data2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5fQxgeS4wy0"
      },
      "source": [
        "## Build dictionary from tokenized documents\n",
        "Next, we build our dictionary based on the tokenized documents. Our dictionary is the collection of all unique words in our corpus. \n",
        "Sometimes, words that are very rare or very frequent are dropped fro teh dictionary. We do not do it for our small dataset. \n",
        "\n",
        "Each unique word is assigned a number in our dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qaZnlvtO1QW"
      },
      "source": [
        "from gensim import corpora\n",
        "dictionary = corpora.Dictionary(text_data1) \n",
        "#dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000) #optional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF3nNDXX6GSo"
      },
      "source": [
        "## Build corpus represenation based on word frequency\n",
        "Then we build the mathematical represenation (i.e., document-term matrix) of our corpus based on the frequency of words appearing in each document. \n",
        "\n",
        "*corpus_bow* contains the frequency of each word (using the words numeric reference based on our dictionary) for each document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioCmnl5p6XZQ"
      },
      "source": [
        "# corpus using word frequencies \n",
        "corpus_bow = [dictionary.doc2bow(text) for text in text_data1]\n",
        "print('Number of unique tokens: %d' % len(dictionary))\n",
        "print('Number of documents: %d' % len(corpus_bow))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14ZV8FKW8Ae7"
      },
      "source": [
        "# one of the documents in our corpus and its numerical representation using word frequencies in corpus_bow\n",
        "print(docs[3])\n",
        "print(text_data1[3])\n",
        "print(corpus_bow[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StBbC-hz6Y_7"
      },
      "source": [
        "## Build corpus representation based on TF-IDF\n",
        "\n",
        "Mere word frequencies are not the best input for our topic modeling (as well as other text analysis). \n",
        "Hence, we also create the mathematical represenation (i.e., document-term matrix) for our corpus based on TF-IDF. \n",
        "Note that the we need to first create the word frequencies in order to derive the tf-idf. \n",
        "\n",
        "TF-IDF indicates the relative importance of a word within a document relative to the corpus (see slides for formula and simple example). \n",
        "\n",
        "For more detail on tf-idf see https://en.wikipedia.org/wiki/Tf-idf "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V6vDSbvwz2H"
      },
      "source": [
        "# corpus using TFIDF\n",
        "tfidf=gensim.models.TfidfModel(corpus_bow)\n",
        "corpus_tfidf=tfidf[corpus_bow]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6WWw8x9808U"
      },
      "source": [
        "# one of the documents in our corpus and its TF-IDF representation in corpus_tfidf\n",
        "print(text_data1[3])\n",
        "print(corpus_tfidf[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mOJFhx6AR8u"
      },
      "source": [
        "### Question 1\n",
        "Based on the values in corpus_bow and corpus_tfidf for the 3rd document (in the above cells). \n",
        "Are all words in the 3rd review equally important in on both document-term matrices? \n",
        "\n",
        "In which representation are the words in the 3rd review weighted based on their total frequency in our corpus? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpE2dCnlAC32"
      },
      "source": [
        "## Using LDA for topic modeling\n",
        "\n",
        "Topic modeling is exploratory in nature and we have to specify the number of topics we want the algorithm to derive. \n",
        "\n",
        "Each topic will be a collection of words from our vocabulary. \n",
        "\n",
        "It is usual to try several values and evaluating the results. \n",
        "We will build topic models with 3, 5, and 10 topics using both corpus_bow (doc-term matrix of term frequencies) and corpus_tfidf (doc-term matric of TF-IDFs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5dQaB9XovX1"
      },
      "source": [
        "# topic models using LDA\n",
        "from gensim.models import LdaModel\n",
        "# using document-term matrix of TF\n",
        "lda_bow_model2 = LdaModel(corpus_bow, num_topics = 2, id2word=dictionary, passes=5,eval_every=None)\n",
        "lda_bow_model3 = LdaModel(corpus_bow, num_topics = 3, id2word=dictionary, passes=5,eval_every=None)\n",
        "lda_bow_model5 = LdaModel(corpus_bow, num_topics = 5, id2word=dictionary, passes=5,eval_every=None)\n",
        "\n",
        "# using document-term matrix of TF-IDF\n",
        "lda_tfidf_model2 = LdaModel(corpus_tfidf, num_topics = 2, id2word=dictionary, passes=5,eval_every=None)\n",
        "lda_tfidf_model3 = LdaModel(corpus_tfidf, num_topics = 3, id2word=dictionary, passes=5,eval_every=None)\n",
        "lda_tfidf_model5 = LdaModel(corpus_tfidf, num_topics = 5, id2word=dictionary, passes=5,eval_every=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSiqH7r2JvdE"
      },
      "source": [
        "## Explore the topic models\n",
        "Let's take a look at the most probable words for each topic in the model with 3 topics. \n",
        "\n",
        "You can check the top words for the other topic models as well. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flSerPzAJrRI"
      },
      "source": [
        "# top words for the 3-topic model based on TF\n",
        "lda_bow_model3.show_topics(num_words=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gciciSitZSe"
      },
      "source": [
        "# top words for the 3-topic model based on TF-IDF\n",
        "lda_tfidf_model3.show_topics(num_words=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLfS8gK0LD6A"
      },
      "source": [
        "### Question 2\n",
        "What seems to be the difference between the topic models (with topics = 3) using TF vs TF-IDF as the input? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNaLv4jYLnYh"
      },
      "source": [
        "## Visualizing topic models \n",
        "An important part in exploratory analysis in the interpretation of results. \n",
        "Visualizing the topics for a topic model can help a lot. \n",
        "\n",
        "We use the LDAvis library that provides methods for visualizing and evluating topics models. \n",
        "\n",
        "The next two visualizations are for the same models we checked the top words above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m70DRJppsODf"
      },
      "source": [
        "import pyLDAvis.gensim_models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDcSiNAFGxgk"
      },
      "source": [
        "# visualizing topics for the model with 3 topics based on TFs\n",
        "lda_display1 = pyLDAvis.gensim_models.prepare(lda_bow_model3, corpus_bow, dictionary, sort_topics=False)\n",
        "pyLDAvis.display(lda_display1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXxNSJbLsGr5"
      },
      "source": [
        "# visualizing topics for the model with 3 topics based on TF-IDF\n",
        "lda_display2 = pyLDAvis.gensim_models.prepare(lda_tfidf_model3, corpus_tfidf, dictionary, sort_topics=False)\n",
        "pyLDAvis.display(lda_display2) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VsR98MtNilo"
      },
      "source": [
        "### Question 3 \n",
        "If you were to chose 3 topics, which model would you choose? why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8anLPFEGNrE8"
      },
      "source": [
        "### Question 4\n",
        "Can you interpret/characterize the 3 topics from the lda model using TF-IDF (lda_tfidf_model3) in terms of most relevant terms in each topic? (explore the above visualization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uljbFvXTPJVd"
      },
      "source": [
        "## Retrieve a document/review's score for each topic\n",
        "\n",
        "Each document in our corpus has a weight for each of the topics in a topic model. \n",
        "The topic with the highest score is the one the document is assigned to.\n",
        "\n",
        "The following cell extracts these scores for one of the documents in our corpus (i.e., one of the reviews)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euTOncm9gZYY"
      },
      "source": [
        "docs[194] # review 35 (note the index starts at 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Swl2GoS_ZVt"
      },
      "source": [
        "# check which topic this document is assigned to in the lda_tfidf_model3  model \n",
        "# and the top words for each topic\n",
        "for index, score in lda_tfidf_model3[corpus_tfidf[194]]:\n",
        "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_tfidf_model3.print_topic(index, 10)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xsow67b4g-U9"
      },
      "source": [
        "### Question 5\n",
        "Based on your interpretation of the 3 topics in question 4, is this review's assignment to the third topic seem reasonable (or surprising)? briefly explain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQW-npKKir1q"
      },
      "source": [
        "###Question 6\n",
        "Which topic (out of the 3 topics in lda_tfidf_model3) is review 194 assigned to? (update and rerun the last two cells to asnwer this question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPYxBP0GPSEm"
      },
      "source": [
        "## What topic would a new review be assigned to?\n",
        "\n",
        "Let's see which topic(s) a new review would be assigned to.\n",
        "\n",
        "While topic models are exploratory in nature, their results can be used as input for text classification models. For example if the resulting topics cleraly characterize different themes in our reviews we can use this topics as categories for our reviews in order to better handle customer complains (e.g., a topic characetrized by bad service but good food, another topic characterized by good atmosphere but mediocre food, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkMymGy3_p9l"
      },
      "source": [
        "new_review=\"The food was too salty but I liked the atmosphere. What's with the attitude?! :-/ \""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPie0Q_BoHae"
      },
      "source": [
        "#applying same pre-processing steps to new review\n",
        "tmp=strip_tags(new_review)\n",
        "tmp=tmp.lower()\n",
        "tmp=strip_multiple_whitespaces(tmp)\n",
        "tmp=strip_punctuation(tmp)\n",
        "tmp=strip_short(tmp)\n",
        "tmp=remove_stopwords(tmp)\n",
        "tmp=WordNetLemmatizer().lemmatize(tmp)\n",
        "new=(list(gensim.utils.tokenize(tmp,deacc=True)))\n",
        "new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nDKV9QCmSPB"
      },
      "source": [
        "# creating a word vector from the tokenized review\n",
        "bow_vector = dictionary.doc2bow(new)\n",
        "bow_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpfI28wrnbZw"
      },
      "source": [
        "# assigning new document to the topics in the lda_tfidf_model3\n",
        "for index, score in lda_tfidf_model3[bow_vector]:\n",
        "    print(\"Score: {}\\t Topic: {}\".format(score, lda_tfidf_model3.print_topic(index, 5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwvloEmw_-54"
      },
      "source": [
        "# assigning new document to the topics in the lda_bow_model3\n",
        "for index, score in lda_bow_model3[bow_vector]:\n",
        "    print(\"Score: {}\\t Topic: {}\".format(score, lda_bow_model3.print_topic(index, 5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbOob0wgqfvV"
      },
      "source": [
        "## Question 7\n",
        "Which of the two above assignments for the new review is more appropriate? i.e. should we assign it to topics generated by lda_tfidf_model3 or lda_bow_model3? \n",
        "\n",
        "\n",
        "Why?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Bi7PIPUz76n"
      },
      "source": [
        "# Additional resources\n",
        "\n",
        "For more details on NLTK, see https://www.nltk.org/ \n",
        "\n",
        "For more details on gensim, see https://radimrehurek.com/gensim/ \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc0ST4288ZhA"
      },
      "source": [
        "## Visualizing Topic difference within/between models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYNZOBmZ64UO"
      },
      "source": [
        "def plot_difference(mdiff, title=\"\", annotation=None):\n",
        "    \"\"\"Plot the difference between models.\n",
        "\n",
        "    Uses plotly as the backend.\"\"\"\n",
        "    import plotly.graph_objs as go\n",
        "    import plotly.offline as py\n",
        "\n",
        "    annotation_html = None\n",
        "    if annotation is not None:\n",
        "        annotation_html = [\n",
        "            [\n",
        "                \"+++ {}<br>--- {}\".format(\", \".join(int_tokens), \", \".join(diff_tokens))\n",
        "                for (int_tokens, diff_tokens) in row\n",
        "            ]\n",
        "            for row in annotation\n",
        "        ]\n",
        "\n",
        "    data = go.Heatmap(z=mdiff, colorscale='RdBu', text=annotation_html)\n",
        "    layout = go.Layout(width=950, height=950, title=title, xaxis=dict(title=\"topic\"), yaxis=dict(title=\"topic\"))\n",
        "    py.iplot(dict(data=[data], layout=layout))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXXIOSEU66Ep"
      },
      "source": [
        "import numpy as np\n",
        "num_topics=5\n",
        "mdiff = np.ones((num_topics, num_topics))\n",
        "np.fill_diagonal(mdiff, 0.)\n",
        "plot_difference(mdiff, title=\"Topic difference (one model) in ideal world\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3qZNMz67QAf"
      },
      "source": [
        "mdiff, annotation = lda_tfidf_model5.diff(lda_tfidf_model5, distance='jaccard', num_words=50)\n",
        "plot_difference(mdiff, title=\"Topic difference (one model) [jaccard distance]\", annotation=annotation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoEwtKya7zSU"
      },
      "source": [
        "mdiff, annotation = lda_tfidf_model5.diff(lda_tfidf_model5, distance='hellinger', num_words=50)\n",
        "plot_difference(mdiff, title=\"Topic difference (one model)[hellinger distance]\", annotation=annotation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpAznnZB77sC"
      },
      "source": [
        "mdiff, annotation = lda_bow_model5.diff(lda_bow_model5, distance='jaccard', num_words=50)\n",
        "plot_difference(mdiff, title=\"Topic difference (two models)[jaccard distance]\", annotation=annotation)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}