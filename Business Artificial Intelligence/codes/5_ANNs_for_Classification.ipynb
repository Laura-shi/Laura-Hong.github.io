{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB6t1KDvgEsI"
      },
      "source": [
        "We became familiar with several ML techniques for Classification. \n",
        "\n",
        "In this activity we will use Artificial Neural Networks (ANN) for classification and compare it with a logistic regression classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43ONt2fUgmtr"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "We will use the ***BankCustomers_ChurnModeling*** dataset.\n",
        "Download the dataset from elearn and upload it to your colab environment (on the left bar under \"Files\", click on Upload and browse to where you downloaded the file - as we did before).  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5EvHk-ffyGP"
      },
      "source": [
        "#import dataset \n",
        "import pandas as pd\n",
        "df = pd.read_csv('BankCustomers_ChurnModeling.csv') \n",
        "#defining input and outcome variables\n",
        "y = df[['LeftBank']]  # y=Whether the customer left the bank (1) or not (0)\n",
        "X = df.iloc[:, 3:13] # X=all other variables except for ID, Surname, row\n",
        "df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuHiWVl7dCAL"
      },
      "source": [
        "The outcome we want to predict is the binary variable \"LeftBank\"; which indicates whether the customer has left the bank (1) or not (0).\n",
        "\n",
        "Hence, we want to build a binary Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yMw4eZLQaXA"
      },
      "source": [
        "#RUN CELL ONCE ONLY! otherwise start from above\n",
        "#dummy encoding Geography and Gender variables \n",
        "X=pd.concat([X,pd.get_dummies(X[['Geography','Gender']])],axis=1) \n",
        "# drop the Original vars, since we now have the binary encoded vars\n",
        "X.drop(X[['Geography','Gender']],axis=1,inplace=True)\n",
        "X.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Etad3e08VLY3"
      },
      "source": [
        "## Scaling the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZNaO2roVAqY"
      },
      "source": [
        "# Feature Scaling, using MinMax scaling\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "sc = MinMaxScaler()\n",
        "X_sc=pd.DataFrame(sc.fit_transform(X))\n",
        "#Note: MinMax scaling Y does not make a difference since it is binary (0/1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrM6lunzflDn"
      },
      "source": [
        "# Training a Logit Classifier using a train/test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOWRyVHIhZ5Q"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "#uncomment ONLY one of the below lines\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123) #train/test split with unscaled data\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X_sc, y, test_size = 0.2, random_state = 123) #with scaled data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_x3e4vxYwl6"
      },
      "source": [
        "To answer Question1: \n",
        "In the above cell use X_sc (2nd line) instead of X to create the testing and training sets with the scaled data. Then rerun the following cells till end of model performance (before k-fold CV)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naiNjlZTVzBG"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "log1 = LogisticRegression(random_state = 0, solver='liblinear')\n",
        "log1.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSr8KCvHWcKz"
      },
      "source": [
        "## Evaluating model performance\n",
        "\n",
        "Evaluate the model on the testing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XG5OGlpWkk6"
      },
      "source": [
        "!pip install scikit-plot  #run once "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHAp2OAGhb54"
      },
      "source": [
        "#evaluating the Logistic Classifier on X_test\n",
        "import sklearn.metrics as metrics\n",
        "import scikitplot as skplt\n",
        "y_pred = log1.predict(X_test)\n",
        "#confusion matrix for the DecTree Classifier\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred,normalize=False) #set normalize=True for percentages\n",
        "#calculating other model evalution metrics\n",
        "print('Precision: '+ str(metrics.precision_score(y_test, y_pred))) #Precision\n",
        "print('Recall:    ' + str(metrics.recall_score(y_test, y_pred))) #Recall\n",
        "print('Accuracy:  ' + str(metrics.accuracy_score(y_test, y_pred)))#Accuracy\n",
        "print('Balanced Acc.: ' + str(metrics.accuracy_score(y_test, y_pred,normalize=True))) # Balanced Accuracy (useful for unbalanced outcome class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-q1gmi9aF36"
      },
      "source": [
        "### Question1\n",
        "Retrain the classifier on the scaled dataset (see above note). \n",
        "Does the model's predictive performance improve? \n",
        "...\n",
        "\n",
        "If so, for which of the three metrics? \n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWqKmZl4zoBe"
      },
      "source": [
        "## Plotting ROC and Precision-Recall Curves (LogisticReg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECwTUpA5sZnG"
      },
      "source": [
        "probas = log1.predict_proba(X_test)\n",
        "#ROC curve \n",
        "skplt.metrics.plot_roc(y_test, probas)\n",
        "#Precision-Recall curve \n",
        "skplt.metrics.plot_precision_recall(y_test, probas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-89DyMYnfwad"
      },
      "source": [
        "## Training and evaluating several classification models using k-fold CV\n",
        "\n",
        "This block is the same we used in activity **2 on Classification**.\n",
        "\n",
        "We train several classifiers using K-fold CV to improve the metric specified for \"scoring=\" (in the previous activity we repeated it for precision, recall, and accuracy)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# Compare Algorithms\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# prepare models\n",
        "models = []\n",
        "models.append(('LogisticReg', LogisticRegression(max_iter=500)))\n",
        "models.append(('K-NN      ', KNeighborsClassifier()))\n",
        "models.append(('DecisTree', DecisionTreeClassifier(criterion = 'entropy')))\n",
        "models.append(('NaiveBayes', GaussianNB()))\n",
        "models.append(('SVM       ', SVC()))\n",
        "#models.append(('RandForest', RandomForestClassifier(n_estimators = 10,criterion = 'entropy')))\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'accuracy' #metric we want to compare ('accuracy')\n",
        "#see https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter for complete list of options\n",
        "for name, model in models:\n",
        "\tkfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=123)\n",
        " \t#Remember, in the next line we specify what data to use X or X_sc (the rest does not change)\n",
        "\tcv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring) \n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "\tprint(msg)\n",
        "# boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison: ' +scoring)\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9ir3Vk8rjy4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG7dlXqSrjZc"
      },
      "source": [
        "#re-running on scaled dataset\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# Compare Algorithms\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# prepare models\n",
        "models = []\n",
        "models.append(('LogisticReg', LogisticRegression(max_iter=500)))\n",
        "models.append(('K-NN      ', KNeighborsClassifier()))\n",
        "models.append(('DecisTree', DecisionTreeClassifier(criterion = 'entropy')))\n",
        "models.append(('NaiveBayes', GaussianNB()))\n",
        "models.append(('SVM       ', SVC()))\n",
        "#models.append(('RandForest', RandomForestClassifier(n_estimators = 10,criterion = 'entropy')))\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'accuracy' #metric we want to compare ('accuracy')\n",
        "#see https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter for complete list of options\n",
        "for name, model in models:\n",
        "\tkfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=123)\n",
        " \t#Remember, in the next line we specify what data to use X or X_sc (the rest does not change)\n",
        "\tcv_results = model_selection.cross_val_score(model, X_sc, y, cv=kfold, scoring=scoring) \n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "\tprint(msg)\n",
        "# boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison: ' +scoring)\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbYDBvx0bXqH"
      },
      "source": [
        "### Question2\n",
        "Why is the performance of the SVM classifier so low? \n",
        "\n",
        "Does training the models on the scaled data fix the issue?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzHIEpEgcHgw"
      },
      "source": [
        "### Question 3\n",
        "Which model has the highest Accuracy when you (correctly) train it on the scaled dataset? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skL7IthAiGeJ"
      },
      "source": [
        "# Using a Neural Network for Classification (predict Customer churn) \n",
        "\n",
        "Let's use an Artificial Neural Network (ANN) for the same problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWBH7lDCtD4d"
      },
      "source": [
        "#install some more things we need \n",
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvCkuWHEqu3i"
      },
      "source": [
        "#%tensorflow_version 2.x\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAYIucfmq0fp"
      },
      "source": [
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeV0DO-1eDjr"
      },
      "source": [
        "# just to make sure we have the right train/test splits before we proceed\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sc, y, test_size = 0.2, random_state = 123) #train/test split with unscaled data\n",
        "#Our predictor variables\n",
        "X_train.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4TzojoRsbsh"
      },
      "source": [
        "## Setting up the NN architecture\n",
        "We define the following architecture for our ANN in the next cell (and make it a function):\n",
        "* 1 input layer with 13 nodes; equal to the number of predictor/input variables (see X_train above)\n",
        "* 2 fully-connected (dense) hidden layer with 32 nodes; we use the Rectifier Linear (ReLu) activation function for the nodes in the hiddern layer. \n",
        "* 1 output node (we have a binary outcome) with a **Sigmoid** activation function.\n",
        "\n",
        "Later, we will add another hidder layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79Oo0uaEi5lp"
      },
      "source": [
        "len(X_train.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpEcTTHpZH9v"
      },
      "source": [
        "#NOTE:run this cell if you want to delete the model and clear tf session\n",
        "tf.keras.backend.clear_session()\n",
        "#del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Di7hQt02pyD"
      },
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([ #keras.Sequential creates a stack of layers (like a placeholder for layers we want to add)\n",
        "    layers.Dense(32, activation='relu', input_shape=[len(X_train.keys())]), \n",
        "    layers.Dense(32, activation='relu'), #uncomment this line to add a 2nd hidden layer later\n",
        "    layers.Dense(1,activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.002) #https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
        "\n",
        "  #using cross-entropy as loss function (high when there are more misclassifications between true and predicted labels)\n",
        "  model.compile(loss='binary_crossentropy', # https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy\n",
        "                optimizer=optimizer, \n",
        "                metrics=['accuracy','AUC','TrueNegatives','TruePositives']) # https://www.tensorflow.org/api_docs/python/tf/keras/metrics \n",
        "  return model\n",
        "\n",
        "#see the links for more details on loss, metrics, and optimizer options"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwCXm286YhXl"
      },
      "source": [
        "#call the above function once to create our model (just initializing it)\n",
        "model=build_model() \n",
        "# show model architecture (see below for details)\n",
        "model.summary() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.weights"
      ],
      "metadata": {
        "id": "elX_IsJYNhE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K7-2ZQXJyx3"
      },
      "source": [
        "For the above NN architecture the number of parameters that can be trained are 1537. How so? \n",
        "we have 1 parameter for each weight and 1 bias parameter for each node (except for our input nodes)\n",
        "*   13x32=416 (weights connecting each input node to each node in the hidden layer) +\n",
        "*   32 (bias parameter for nodes in the 1st hidden layer) \n",
        "*   = 448 parameters\n",
        "*   32x32=1024 (weights connecting each node in the 1st hidden layer to 32 nodes in the 2nd hidden layer) +\n",
        "*   32 (bias parameters for nodes in the 2nd hidden layer) = 1056 parameters\n",
        "*   = 1056\n",
        "*   32 (weights connecting 32 nodes of the 2nd hidden layer to the ouput node) + 1 (bias for ouput node)\n",
        "*   = 33\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzpRgqCJzvG0"
      },
      "source": [
        "#making sure our X_train has the right shape and we it to our NN\n",
        "model.predict((X_train[:5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c32uG30JtEdt"
      },
      "source": [
        "## Training the NN model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haZ4dZXtVFWq"
      },
      "source": [
        "# Feature Scaling, we will use MinMax scaling\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "sc = MinMaxScaler() \n",
        "#sc.fit_transform(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao84Yq2mg6OO"
      },
      "source": [
        "#training the NN on scaled data (NOTE: this is the right way!)\n",
        "EPOCHS = 100\n",
        "history = model.fit(\n",
        "  X_train,y_train,\n",
        "  epochs=EPOCHS, validation_split = 0.1, verbose=0, #NN trains on the other 90%, validates on 10% in each epoch\n",
        "  callbacks=[tfdocs.modeling.EpochDots()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_ZD4GOEhUvA"
      },
      "source": [
        "#take a look at the loss values for the first and last 5 epochs\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.head(5), hist.tail(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN5syYa7uAfL"
      },
      "source": [
        "Our loss here is \"binary cross-entropy\" (lower is better). \n",
        "But we will plot Accuracy since you are more familiar with this metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3lHZJ_mhgWu"
      },
      "source": [
        "#plotting accuracy values per epoch; shows how accuracy increases as we train the NN\n",
        "plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)\n",
        "plotter.plot({'Basic': history}, metric = \"accuracy\")\n",
        "plt.ylim([0, 1]) \n",
        "plt.ylabel('Accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)\n",
        "plotter.plot({'Basic': history}, metric = \"loss\")\n",
        "plt.ylim([0, 1]) \n",
        "plt.ylabel('binary cross-entropy')"
      ],
      "metadata": {
        "id": "JJVKEWyJlXPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2UnVzPUzxXn"
      },
      "source": [
        "### Question 4\n",
        "Does the NN model training converge? If so, around which epoch?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBdP8s-jb8E2"
      },
      "source": [
        "What metric do you look at to answer the above question?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhHF2O5JyZjA"
      },
      "source": [
        "## NN model performance "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1nqAOYsq129"
      },
      "source": [
        "#using the neural network to predict probability of outcome=1 for X_test\n",
        "model.predict(X_test)\n",
        "# we consider an obs with a probability of greater&equal than 0.5 to belong to the 1 class\n",
        "y_pred = model.predict(X_test)[:,0]>=0.5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3Jj8NpM01OD"
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "import scikitplot as skplt\n",
        "#confusion matrix for the DecTree Classifier\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred,normalize=False) #set normalize=True for percentages\n",
        "#calculating other model evalution metrics\n",
        "print('Precision: '+ str(metrics.precision_score(y_test, y_pred))) #Precision\n",
        "print('Recall:    ' + str(metrics.recall_score(y_test, y_pred))) #Recall\n",
        "print('Accuracy:  ' + str(metrics.accuracy_score(y_test, y_pred)))#Accuracy\n",
        "print('Balanced Acc.: ' + str(metrics.accuracy_score(y_test, y_pred,normalize=True)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDpD67peykFd"
      },
      "source": [
        "### Question 5\n",
        "Does this NN model (13-32-32-1 architecture) have a better Accuracy than the previous classifiers?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCoCXdUVzY-8"
      },
      "source": [
        "## Plotting ROC and Precision-Recall Curves (NN model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX1AUjm0vLnF"
      },
      "source": [
        "import numpy as np\n",
        "c1=1-model.predict(X_test)\n",
        "c0=model.predict(X_test)\n",
        "probas=np.concatenate((c1,c0),axis=1)\n",
        "#ROC curve \n",
        "skplt.metrics.plot_roc(y_test, probas)\n",
        "#Precision-Recall curve \n",
        "skplt.metrics.plot_precision_recall(y_test, probas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NWKzQycX1De"
      },
      "source": [
        "### BONUS QUESTION (optional)\n",
        "Create a neural network architecture with one hidden layer (instead of 2; 13-32-1 architecture), train it, and compare its performance with the first NN (in terms of accuracy, precision, and recall).\n",
        "\n",
        "You can copy the required cells from above and modify them."
      ]
    }
  ]
}