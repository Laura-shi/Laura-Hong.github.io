{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11_SentimentAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNhL3Dc5x986",
        "colab_type": "text"
      },
      "source": [
        "#Sentiment Analysis\n",
        "\n",
        "Sentiment analysis (a.k.a opinion mining), in its simple form, identifies whether a piece of text has negative or positive emotion. \n",
        "Sentiment analysis is a supervised learning task, where our algorithm learns how to classify text as positive/negative from labeled textual data. \n",
        "There can be more than two sentiments (e.g., neutral, happy, etc.), in which case we deal with a text classification task with multiple outcomes. \n",
        "\n",
        "Sentiment analysis is used in various business applications involving textual data, such as performance monitoring (based on user feedback), assessing brand reputation, market research for product launches. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOuhbg-XG312",
        "colab_type": "text"
      },
      "source": [
        "## Scenario\n",
        "We will use a dataset on restaurant reviews for this exercise. The \n",
        "sentiment for each review has been manually labeled for this dataset: positive=1, negative=0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRbey1H5wVQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing restaurant reviews dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "df=pd.read_csv('Restaurant_Reviews.tsv',delimiter=\"\\t\")\n",
        "df.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDKrAAeNw2IO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=df.Review\n",
        "Y=df.Sentiment\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jL5tOfMb4dA",
        "colab_type": "text"
      },
      "source": [
        "#Sentiment Analysis using BOW approach and ML models\n",
        "We will first use the bag-of-words approach for text processing and classic ML models such as Logistic Regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsc8TYtw_dPO",
        "colab_type": "text"
      },
      "source": [
        "## Text pre-processing\n",
        "\n",
        "First, we need to pre-process the text data. \n",
        "We use another library this time for the pre-rocessing steps. \n",
        "\n",
        "The *TfidfVectorizer* function lower-cases all words, removes punctuations and stopwords, tokenizes the documents, and derives the tf-idf document-term matrix. \n",
        "When we fit it on our corpus it also derives the vocabulary. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdHnWcohKpmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# to include n-grams, change the ngram_range below\n",
        "tfidf = TfidfVectorizer(min_df=1, ngram_range=(1, 1), stop_words='english',sublinear_tf=True)\n",
        "X_tfidf = tfidf.fit_transform(X).toarray()\n",
        "X_tfidf.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TydZBcjzVbjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's take a look at a review and its tokens from the tf-idf matrix\n",
        "print(X[17]),\n",
        "tfidf.inverse_transform(X_tfidf[17])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkVycVCK7yXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of tokens in each document (review) of our corpus\n",
        "num_tokens = [np.count_nonzero(tokens) for tokens in X_tfidf]\n",
        "num_tokens[17]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q339lNipT29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of words in our vocabulary\n",
        "num_words=len(tfidf.vocabulary_)\n",
        "num_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiovQh8Ii1ja",
        "colab_type": "text"
      },
      "source": [
        "## Split the data into test/train\n",
        "We split the tranformed data (i.e, the tf-idf doc-term matrix) into testing and training set. I keep a small part for the testing set here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSuOFzlUi1Ah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, Y, test_size=0.20,random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEf8fk0eIJx2",
        "colab_type": "text"
      },
      "source": [
        "## ML models for text classification\n",
        "Our outcome is binary (positive/negative), so we will try Logistic Regression, Naive Bayes, and multinomial Naive Bayes (good choice for text classification with multiple outcomes).\n",
        "\n",
        "We train all these models using k-fold Cross validation on the training set (X_train). \n",
        "For each run in our k-fold CV, X_train is split into a training and validation set. We will use the testing set (X_test) in the next part to evaluate the selected model. \n",
        "\n",
        "For more details on *Multinomial Naive Bayes* and its comparison to Naive Bayes, see https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_naive_Bayes and \n",
        "https://stats.stackexchange.com/questions/33185/difference-between-naive-bayes-multinomial-naive-bayes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzyv9GiZKZ3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import warnings\n",
        "#warnings.filterwarnings('ignore')\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "#from sklearn.svm import SVC\n",
        "\n",
        "# prepare models\n",
        "models = []\n",
        "models.append(('LogisticReg', LogisticRegression()))\n",
        "models.append(('NaiveBayes', GaussianNB()))\n",
        "models.append(('MultinomialNB', MultinomialNB()))\n",
        "#models.append(('SVM', SVC()))\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'accuracy' #metric we want to compare\n",
        "\n",
        "for name, model in models:\n",
        "\tkfold = model_selection.KFold(n_splits=5,shuffle=True, random_state=0)\n",
        " #use X_tfidf, Y  in following line to run on complete dataset #X_train,y_train\n",
        "\tcv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "\tprint(msg)\n",
        "# boxplot model comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparing Text classification models: ' +scoring)\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YULdg3n8NbX",
        "colab_type": "text"
      },
      "source": [
        "### Question 1\n",
        "Which model has a better accuracy in labeling negative/positive reviews?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjGisRNNgpEb",
        "colab_type": "text"
      },
      "source": [
        "### Question 2\n",
        "Derive the vocabulary again, and this time include 2-grams (go back to Text pre-processing section, include 2-grams and re-run the steps till the above cell). Does it improve predictive performance for any of the above modelsy?  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2A8US_2cUU0",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating Logistic Regression classifer  on test data\n",
        "\n",
        "Let's pick the logistic regression classifier and evaluate it on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyZl_wIcaGxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Logistic regression\n",
        "model_LogReg = LogisticRegression(random_state=0)\n",
        "model_LogReg.fit(X_train, y_train)\n",
        "\n",
        "#y_pred_proba = model_LogReg.predict_proba(X_test)\n",
        "y_pred = model_LogReg.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCHL_7-7ZnLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install scikit-plot\n",
        "import scikitplot as skplt\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred)\n",
        "\n",
        "from sklearn import metrics\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)), #Accuracy\n",
        "print(\"Balanced Acc.:\",metrics.balanced_accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivf0YsUO7EDs",
        "colab_type": "text"
      },
      "source": [
        "## Label a new review using the logistic regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-4sPSyh6CcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# label a new review using our model\n",
        "new_review= ['food can be better'] \n",
        "#process new review into doc-term matrix \n",
        "X_new=tfidf.transform(new_review) \n",
        "X_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4ZSdBMf6ntF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model_LogReg.predict_proba(X_new)) #predict class probabilities \n",
        "print(model_LogReg.predict(X_new)) #predict outcome class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL_NkzkZ8EOD",
        "colab_type": "text"
      },
      "source": [
        "### Question 3\n",
        "Does the model label the new input as negative or positive? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm2rUUlsKOPl",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment analysis using word embeddings and RNNs (LSTM/GRU)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S2vPhiTjhjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras as tk\n",
        "from tensorflow.keras.layers import Embedding, Dense, Dropout, LSTM, GRU, Bidirectional,RNN\n",
        "tk.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJrxMa5DQrv0",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing text data for RNN \n",
        "To use Recurrent neural network architectures for text classification, we need to pre-process text data little differently from what we did above.\n",
        "* We create a vocabulary by tokenizing all document in our corpus. \n",
        "* Then, we sequence each document into integer-tokens using the derived vocabulary. \n",
        "* To correctly feed each document input to the RNN, each sequenced document has to have the same length. Therefore, we pad/truncate documents. \n",
        "* We use an embedding layer to convert the integer-vectors into real-valued vectors (more details in section below)\n",
        "* The output of the embedding layer is fed into our Recurrent NN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JdGvtbuo5U8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer #removes punctuations and lower-cases all words before tokenizing\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xFDoSq5L4PC",
        "colab_type": "text"
      },
      "source": [
        "### Why am I not using all the pre-processing steps here?!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OItIjTRMHczm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "from gensim.parsing.preprocessing import remove_stopwords,strip_tags,strip_multiple_whitespaces,strip_punctuation\n",
        "import nltk\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEKLwU4sH01a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp=X.apply(strip_multiple_whitespaces)\n",
        "tmp=tmp.apply(str.lower)\n",
        "tmp=tmp.apply(strip_punctuation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ22sr09IPcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp[98]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KINVgnb7JUfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp.apply(remove_stopwords)[98]\n",
        "#tmp.apply(WordNetLemmatizer().lemmatize)[29]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EIOW-sFULB5",
        "colab_type": "text"
      },
      "source": [
        "### Tokenizing, sequencing, padding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2WssYKXf-71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using the tf.keras tokenizer \n",
        "num_words=1800 #number of words to keep in vocabulary, most common words are kept\n",
        "tokenizer = Tokenizer(num_words=num_words)\n",
        "tokenizer.fit_on_texts(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6tSqF4vcflR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(tokenizer.word_index) # total number of unique words in our corpus\n",
        "#tokenizer.word_index # run to see what integer is assigned to each word after tokenization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5LREy5ghXB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sequencing our text data (tokenizing based)\n",
        "X_tokens=tokenizer.texts_to_sequences(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhkIerJ3h9GH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some values we need for the next step\n",
        "num_tokens= np.array([np.count_nonzero(tokens) for tokens in X_tokens]) #number of tokens in each document\n",
        "max_tokens=max(num_tokens)\n",
        "max_tokens,num_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsoypBbCipok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pad the token sequence for each document so that all documents are of equal length\n",
        "X_tokens_pad = pad_sequences(X_tokens, maxlen=max_tokens,\n",
        "                            padding='pre', truncating='pre')\n",
        "X_tokens_pad.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hIEeJqijwpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's see what happened to a single document at each step\n",
        "print(X[17]) #the textual data\n",
        "print(X_tokens[17]) #the tokenized sequence\n",
        "print(X_tokens_pad[17]) #the padded sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hubATLa7L8-m",
        "colab_type": "text"
      },
      "source": [
        "## Splitting the processed data into train/test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znkaFH4Hy6hR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split processed data into train/test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tokens_pad, Y, test_size=0.2,random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6pEI0aU1aOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape, X_test.shape, y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MNHA1Gtpu1s",
        "colab_type": "text"
      },
      "source": [
        "### Question 4\n",
        "How many words does the longest document in X_train have? \n",
        "\n",
        "How about the longest document in X_test? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr5QFsyzL97u",
        "colab_type": "text"
      },
      "source": [
        "## Recurrent neural network 1\n",
        "The first layer is an embedding layer that converts the integer-tokens into vector values. \n",
        "This is needed since the integer-tokens (X_tokens) can have values between 0 and 1800 (for our vocabulary of 1800 words), but the RNN cannot work with such wide range. The learned vector values range from -1 to 1.\n",
        "\n",
        "The embedding-layer is trained as part of the RNN and learns to map words with similar meaning to similar embedding vectors. We will try an example below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tziRcOnUhGxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_size=16 #size of the embedding vector\n",
        "\n",
        "model_RNN = tk.models.Sequential()\n",
        "\n",
        "model_RNN.add(Embedding(input_dim=num_words,\n",
        "                    output_dim=embedding_size,\n",
        "                    input_length=max_tokens,\n",
        "                    name='layer_embedding'))\n",
        "\n",
        "model_RNN.add(LSTM(units=20,dropout=0.2)) # add an LSTM layer with dropout\n",
        "#model_RNN.add(GRU(units=20,dropout=0.2)) #add a GRU layer\n",
        "\n",
        "# for sequences other than time series, an RNN model can sometimes perform better if it processes a sequence both forwards and backwards. \n",
        "# For example, to predict the next word in a sentence it is useful to have the context around the word.\n",
        "# the Bidirectional wrapper adds such layers.\n",
        "#model_RNN.add(Bidirectional(LSTM(units=16,dropout=0.2)))\n",
        "\n",
        "model_RNN.add(Dropout(0.2)) # add a dropout layer\n",
        "\n",
        "model_RNN.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "optimizer=tk.optimizers.Adam() # selecting the optimizer\n",
        "\n",
        "# compiling the model\n",
        "model_RNN.compile(loss='binary_crossentropy', #mae,mse\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_RNN.summary() # model overview"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqIdUEMOguSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make sure the input data can be feed to the RNN\n",
        "model_RNN.predict(X_train[:3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLdwnUXuir5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the RNN model \n",
        "# train and test sets: using all data in train set for learning and test set for validation\n",
        "history = model_RNN.fit(X_train, y_train, validation_data=(X_test, y_test),epochs=10, verbose=1)\n",
        "# train, validate, test sets: further splitting training set into train/validation\n",
        "#history = model_RNN.fit(X_train, y_train,validation_split=0.2,epochs=10, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHd2104wBZ1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot training and validation accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'],label=\"training\")\n",
        "plt.plot(history.history['val_accuracy'],label=\"validation\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVTf7dL-_O4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot training and validation loss\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'],label=\"training\")\n",
        "plt.plot(history.history['val_loss'],label=\"validation\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HTVJB1aDVKA",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate the RNN model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs1i2DLRCzTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=(model_RNN.predict(X_test)>0.5).astype('int32')\n",
        "\n",
        "import scikitplot as skplt\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred)\n",
        "\n",
        "from sklearn import metrics\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)), #Accuracy\n",
        "print(\"Balanced Acc.:\",metrics.balanced_accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snuvwlVhq7sA",
        "colab_type": "text"
      },
      "source": [
        "### Question 5\n",
        "Would using more training-epochs improve performance? you can retrain the model to verify.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4cU8lf1j_hL",
        "colab_type": "text"
      },
      "source": [
        "### Question 6\n",
        "Is the model overfitting the training data? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrODDEg3tYH2",
        "colab_type": "text"
      },
      "source": [
        "### Question 7\n",
        "Change the LSTM layer to a GRU layer. Does the RNN with GRU units have a better performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_E2JInLkj8L",
        "colab_type": "text"
      },
      "source": [
        "### Question 8\n",
        "Would the model overfit the data if we did not include the dropout layer and dropout inside the LSTM/GRU units? you can change the network architecture and retrain it to verify. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzTiNANUk4o2",
        "colab_type": "text"
      },
      "source": [
        "### Question 9 (optional)\n",
        "Increase the size of the embedding-vectors to 64 (from 16). Does it affect model performance? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru16mYTmk4CP",
        "colab_type": "text"
      },
      "source": [
        "### Question 10\n",
        "Decrease the number of words in the vocabulary from 2000 to 1500. Does it affect performance? \n",
        "\n",
        "*Go to the \"Tokenizing, sequencing, padding\" section to re-initialize the tokenizer and rerun subsequent steps.* \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rjHMTv0l4i0",
        "colab_type": "text"
      },
      "source": [
        "### Question 11\n",
        "Use 'post' for padding and truncating the sequenced tokens in pad_sequences() (*Go to the \"Tokenizing, sequencing, padding\" section and rerun subsequent steps*). Does it affect model performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obcJUde6ai2G",
        "colab_type": "text"
      },
      "source": [
        "## Classify a new review using the RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E5KDBSvao0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_review= ['food can be better'] \n",
        "new_sequence=tokenizer.texts_to_sequences(new_review) # tokenize and sequence\n",
        "new_seq_pad=pad_sequences(new_sequence, maxlen=max_tokens,padding='pre') # pad it\n",
        "new_seq_pad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPw4g6CebPQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_RNN.predict(new_seq_pad) # predict probability \n",
        "#np.argmax(model_RNN.predict(X),axis=-1) #for multiclass outcomes\n",
        "(model_RNN.predict(new_seq_pad)>0.5).astype('int32') #for binary outcomes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwohWWkYJIEG",
        "colab_type": "text"
      },
      "source": [
        "## Extracing word embeddings\n",
        "Earlier we mentioned word embeddings and that we have an embedding layer which learns how to map words (in the form of integer-tokens) to vectors as we train the neural network. \n",
        "\n",
        "The distance between two word vectors indicate their similarity and we can derive these vectors for any word in our vocabulary from the embedding layer. \n",
        "\n",
        "We will use the cosine distance between two words. Cosine values can range from [-1,1], so the distance can range from 0 to 2 (in our complex vector space): \n",
        "* close to 0: two words have the same meaning \n",
        "* close to 2: two words are antonyms\n",
        "\n",
        "For more details on cosine similarity, see https://en.wikipedia.org/wiki/Cosine_similarity "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMH4ojV8SS_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract the embedding layer from the RNN architecture\n",
        "embedding_weights=model_RNN.get_layer('layer_embedding').get_weights()[0]\n",
        "\n",
        "# vector for a word in our vocabulary\n",
        "print(tokenizer.word_index['food']) # integer for word in our vocabulary\n",
        "# word vector representation as learned in the embedding layer\n",
        "embedding_weights[tokenizer.word_index['food']]  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik9DQ0fzeT6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's calculate distance between any two words in our vocabulary\n",
        "from scipy.spatial.distance import cdist\n",
        "float(cdist([embedding_weights[tokenizer.word_index['delicious']]],\n",
        "            [embedding_weights[tokenizer.word_index['bad']]],\n",
        "            metric='cosine'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE94zsaIguY8",
        "colab_type": "text"
      },
      "source": [
        "### Question 12\n",
        "How close are the words *spaghetti* and *pizza* based on the word-vectors learned in our embedding layer? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9NxAn7NoQ53",
        "colab_type": "text"
      },
      "source": [
        "### Question 13\n",
        "Is the word *delicious* more similar in meaning to *good* or *bad*?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjDoriOIWKip",
        "colab_type": "text"
      },
      "source": [
        "## Recurrent Neural Network 2\n",
        "\n",
        "Let's try another architecture 3 LSTM layers (i.e., deep RNN) and see if it has a better predictive performance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JBCfRWHPWLXY",
        "colab": {}
      },
      "source": [
        "embedding_size=16 #size of the embedding vector\n",
        "\n",
        "model_2 = tk.models.Sequential()\n",
        "\n",
        "model_2.add(Embedding(input_dim=num_words,\n",
        "                    output_dim=embedding_size,\n",
        "                    input_length=max_tokens,\n",
        "                    name='layer_embedding'))\n",
        "\n",
        "model_2.add(LSTM(units=32, return_sequences=True,dropout=0.2))\n",
        "model_2.add(Dropout(0.2))\n",
        "\n",
        "model_2.add(LSTM(units=16, return_sequences=True,dropout=0.2))\n",
        "model_2.add(Dropout(0.2))\n",
        "\n",
        "model_2.add(LSTM(units=8,dropout=0.2))\n",
        "model_2.add(Dropout(0.2))\n",
        "\n",
        "model_2.add(Dense(1, activation='sigmoid')) # use softmax  for multiclass outcomes\n",
        "\n",
        "optimizer=tk.optimizers.Adam() # selecting the optimizer\n",
        "\n",
        "# compiling the model\n",
        "model_2.compile(loss='binary_crossentropy', \n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "# for multiclass outcomes use categorical_crossentropy or sparse_categorical_crossentropy\n",
        "# categorical_crossentropy, when outcomes are one-hot encoded\n",
        "# sparse_categorical_crossentropy, when outcomes are labeled as integers\n",
        "\n",
        "model_2.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llJqVjK9maBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit/train the model\n",
        "history2 = model_2.fit(X_train, y_train,validation_split=0.2,epochs=30, verbose=1)\n",
        "#history2 = model_2.fit(X_train, y_train,validation_data=(X_test, y_test),epochs=30, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2RfyzY5mgmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot training and validation accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history2.history['accuracy'],label=\"training\")\n",
        "plt.plot(history2.history['val_accuracy'],label=\"validation\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzFH102ymltY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate model performance on test set\n",
        "y_pred=(model_2.predict(X_test)>0.5).astype('int32')\n",
        "\n",
        "import scikitplot as skplt\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred)\n",
        "\n",
        "from sklearn import metrics\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)), #Accuracy\n",
        "print(\"Balanced Acc.:\",metrics.balanced_accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pv-e2tspnYcS",
        "colab_type": "text"
      },
      "source": [
        "###Question 14\n",
        "Does the second model have better performance in terms of accuracy?"
      ]
    }
  ]
}