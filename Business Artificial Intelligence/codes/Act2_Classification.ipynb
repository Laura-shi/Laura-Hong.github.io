{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Act2_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVE_CE0sr7L7"
      },
      "source": [
        "#Classification\n",
        "Classification is another supervised learning task where an algorithm learns a function to map an input to an output class.\n",
        "\n",
        "In this activity we will become familiar with several techniques for predicting categorical outcomes. Such models are also called classifiers (they classify an input as one of the outcome groups)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ2efaGgr-Jc"
      },
      "source": [
        "##Breast Cancer Dataset\n",
        "This is one of the classic datasets used for classification. It contains actual values about tumor characteristics and the diagnosis of the tumor as benign or malignant.\n",
        "\n",
        "Two version of this dataset can be found at \n",
        "*   https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic) \n",
        "*   https://archive.ics.uci.edu/ml/support/Breast+Cancer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTUWSdq0r0oL"
      },
      "source": [
        "#loading the breast cancer dataset\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names) #load the dataset as a dataframe\n",
        "df_y = pd.DataFrame(data.target, columns=['Malignant']) # in original dataset Benign=1, Malignant=0 \n",
        "#we named the target column \"Malignant\" and will recode the variable (Malignant=1, Benign=0) correspondingly\n",
        "df=pd.concat([df,1-df_y],axis=1)\n",
        "df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WcNO7XsEMRa"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKXJt52-U37p"
      },
      "source": [
        "#212 observations are Malignant tumors, 357 are benign\n",
        "df['Malignant'].sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARzY_WNu9EaT"
      },
      "source": [
        "#let's take a look at the summary statistics\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67pmqeF96JIx"
      },
      "source": [
        "#to save the loaded file as csv, uncomment next line and run this cell\n",
        "#df.to_csv('breastcancer.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lbVcMvvsXO1"
      },
      "source": [
        "#check variables for NULL or NA values\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqr6cpES4ytC"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJbxE_Y-U2cF"
      },
      "source": [
        "#visually explore the data: correlation matrix of the dataset\n",
        "import seaborn as sb\n",
        "cormatrix=df.corr()\n",
        "sb.heatmap(cormatrix,cmap='Blues') \n",
        "#cmap(colormap) options: 'Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds','YlOrBr', 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu','GnBu', 'PuBu', 'YlGnBu', 'PuBuGn', 'BuGn', 'YlGn'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj4zNLQ7alf7"
      },
      "source": [
        "##preparing the data for model training\n",
        "#Outcome variable y: binary (Malignant=1, Benign=0)\n",
        "y = df[['Malignant']]  \n",
        "X = df.drop('Malignant',axis=1) #all other variables used as potential predictors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg9BVLAkmako"
      },
      "source": [
        "None of the potential predictor/input/X variables are categorical, so we won't need to encode them (i.e., dummy or OneHot encoding). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aVVXrE4a6cC"
      },
      "source": [
        "X.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gCUNlYxJ2Bm"
      },
      "source": [
        "y.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsdhKN9LYZdX"
      },
      "source": [
        "## Splitting the data into Train/Test set\n",
        "We will split the data intro train and test set, try several classifications models, and evaluate their predicitve performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VfCF42abPBb"
      },
      "source": [
        "#splitting the dataset into training (75%) and testing (25%)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 123)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUJDL1X9baLe"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "#uncomment ONLY one the following two, depending on how you want to scale the data\n",
        "sc = StandardScaler() #standardization\n",
        "#sc = MinMaxScaler() #minmax scaling\n",
        "X_train_sc=sc.fit_transform(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcCDfWjqK97X"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# Let's compare the histograms of pre/post scaling for one variable (\"mean radius\") in our training data (X_train)\n",
        "import matplotlib.pyplot as plt\n",
        "fig, axs = plt.subplots(ncols=2)\n",
        "sb.distplot(X_train[X_train.columns[0]], ax=axs[0])\n",
        "sb.distplot(X_train_sc[[0]], ax=axs[1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTk5tzbJLUkY"
      },
      "source": [
        "fig, axs = plt.subplots(ncols=2)\n",
        "sb.distplot(X_train[X_train.columns[3]], ax=axs[0])\n",
        "sb.distplot(X_train_sc[[3]], ax=axs[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eNOqqUePh4t"
      },
      "source": [
        "Now rescale X_train using the **minmax** scaler and rerun the plots in the previous cell for some variable (e.g., pick one column from 0 to 29). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY8fQxuJmJ8l"
      },
      "source": [
        "### Question 1\r\n",
        "Can you explain what happened after using a different scaler?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs06o0jsQO1e"
      },
      "source": [
        "answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiw5IBzbbaPJ"
      },
      "source": [
        "##Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKQZPcaVMaIg"
      },
      "source": [
        "#using logistic regression \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic1 = LogisticRegression(random_state = 0, solver='liblinear')\n",
        "logistic1.fit(X_train_sc, y_train) #fitting the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBOmj75DRCvP"
      },
      "source": [
        "#using the trained model to predict outcome values for the test data (X_test)\n",
        "y_pred = logistic1.predict(sc.transform(X_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3jRtbrHZGRv"
      },
      "source": [
        "### Question 2\r\n",
        "What is the problem in the previous step? Did we miss anything?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4dMSlcq-LHW"
      },
      "source": [
        "answer here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtbVuEJoRGY8"
      },
      "source": [
        "#fix issue before proceeding!!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSFt8bXUbBfq"
      },
      "source": [
        "##Model Evaluation\n",
        "we can use sklearn.metrics to calculate performance metrics (the code is provided by commented out).\n",
        "\n",
        "Another option is scikitplot (which runs on top of sklearn) to create more appealing display for evaluation metrics such as the confusion matrix and various model evaluation plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBYSScFZZSb9"
      },
      "source": [
        "#evaluating model performance using sklearn metrics\n",
        "#see https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics  for definition/overview of each metric\n",
        "import sklearn.metrics as metrics\n",
        "metrics.confusion_matrix(y_test, y_pred) #confusion matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1ceU2JBaoFI"
      },
      "source": [
        "#!pip install scikit-plot #run once to install library\n",
        "#using scikit plot for model evaluation\n",
        "import scikitplot as skplt\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred) #confusion matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiv0-dItdVi0"
      },
      "source": [
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred, normalize=True) #normalized confusion matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq0DWYbioT6X"
      },
      "source": [
        "#Let's take a look at model's Precision, Recall, and Accuracy\n",
        "(metrics.precision_score(y_test, y_pred), #Precision\n",
        "metrics.recall_score(y_test, y_pred), #Recall\n",
        "metrics.accuracy_score(y_test, y_pred), #Accuracy\n",
        "metrics.balanced_accuracy_score(y_test, y_pred)) #Balanced Accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkEgTKX7eAHN"
      },
      "source": [
        "#calculate probabilty of each observation in X-test to belong to either outcome class; Benign=0 , Malignant=1\n",
        "y_pred_prob=logistic1.predict_proba(sc.fit_transform(X_test))\n",
        "y_pred_prob.round(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P85SppQ9esNt"
      },
      "source": [
        "#plotting the ROC curve to evalute the model's aggregate performance\n",
        "skplt.metrics.plot_roc_curve(y_test,y_pred_prob)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxduizAgQd0B"
      },
      "source": [
        "#plot precision-recall curve\r\n",
        "skplt.metrics.plot_precision_recall_curve(y_test,y_pred_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AWI0ngsvdNl"
      },
      "source": [
        "##Decision Tree Classification \n",
        "\n",
        "Learn more at https://scikit-learn.org/stable/modules/tree.html#tree "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8beH_jivn_e"
      },
      "source": [
        "#using the Decision Tree Classifier from sklearn\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "DecTree1 = DecisionTreeClassifier(criterion = 'entropy', random_state = 123) #change metric to 'gini' and rerun\n",
        "DecTree1.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAUVay9iv-Se"
      },
      "source": [
        "#using the model to predict outcomes for X_test\n",
        "y_pred = DecTree1.predict(X_test) \n",
        "#confusion matrix for the DecTree Classifier\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HGEKGpERHCW"
      },
      "source": [
        "#calculating other model evalution metrics\r\n",
        "(metrics.precision_score(y_test, y_pred), #Precision\r\n",
        "metrics.recall_score(y_test, y_pred), #Recall\r\n",
        "metrics.accuracy_score(y_test, y_pred),#Accuracy\r\n",
        "metrics.accuracy_score(y_test, y_pred,normalize=True)) # Balanced Accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5axHJKle1OPV"
      },
      "source": [
        "Change the split criterion for the Decision Tree to 'gini' and rerun the model and evalution. \n",
        "### Question 3\n",
        "Does it improve the model? which metric did you consider for your answer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzI8eNSUmpg3"
      },
      "source": [
        "answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC8LZtoE2CK0"
      },
      "source": [
        "## Cross validation \n",
        "Is an approach to evalute machine learning models. CV helps with **overfitting** in supervised learning. It is also use to for model selection (selecting the best performing model between several candidates).\n",
        "\n",
        "https://scikit-learn.org/stable/modules/cross_validation.html \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLjW2kd9T9NK"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "KNN1=KNeighborsClassifier(n_neighbors=5)\r\n",
        "KNN1.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-p0uZtMU6l8"
      },
      "source": [
        "y_pred=KNN1.predict(X_test)\r\n",
        "(metrics.precision_score(y_test, y_pred), #Precision\r\n",
        "metrics.recall_score(y_test, y_pred), #Recall\r\n",
        "metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjQBGwHOqHxw"
      },
      "source": [
        "##Comparing several models (using CV for model validation)\n",
        "Now we will put everything together and compare several models based on several performance metrics. We use k-fold cross-validation to evaluate each model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG7dlXqSrjZc"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# Compare Algorithms\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# prepare models\n",
        "models = []\n",
        "models.append(('LogisticReg', LogisticRegression(max_iter=500)))\n",
        "models.append(('K-NN      ', KNeighborsClassifier()))\n",
        "models.append(('DecisTree', DecisionTreeClassifier(criterion = 'entropy')))\n",
        "models.append(('NaiveBayes', GaussianNB()))\n",
        "models.append(('SVM       ', SVC())) # add a SVM classifieer\n",
        "# the next line adds a RandomForest classifier\n",
        "models.append(('RandForest', RandomForestClassifier(n_estimators = 10,criterion = 'entropy')))\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'recall' #metric we want to compare\n",
        "#see https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter for complete list of options\n",
        "for name, model in models:\n",
        "\tkfold = model_selection.KFold(n_splits=10, random_state=123)\n",
        "\tcv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "\tprint(msg)\n",
        "# boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison: ' +scoring)\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF6c3nKDuxld"
      },
      "source": [
        "### Question 4\r\n",
        "Which model has the best Accuracy? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA_cXqGA-PMT"
      },
      "source": [
        "answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOIHJpifu0Kl"
      },
      "source": [
        "change the scoring metric in the previous code cell as needed to answer the following questions. For example: \r\n",
        "* scoring='accuracy'\r\n",
        "* scoring='precision'\r\n",
        "* scoring='recall'\r\n",
        "\r\n",
        "see https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter for a comprehensive list\r\n",
        "### Question 5\r\n",
        "Which model has the best Precision for the Malignant (1) class? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG51vtXl-SJk"
      },
      "source": [
        "answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt0fJd9uu-yf"
      },
      "source": [
        "### Question 6\r\n",
        "Which model has the best Recall (for the Malignant class)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXy2BlSH-S1r"
      },
      "source": [
        "answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34vuDdYg65j0"
      },
      "source": [
        "Let's uncomment the line for addding a RandomForest Classifier and rerun the previous cell. \n",
        "### Question 7\n",
        "Which model has a better predictive performance now? what metric did you use?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG8eBjZv-TuZ"
      },
      "source": [
        "answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n7RXS3Y4r9i"
      },
      "source": [
        "## Iris dataset (3 outcome classes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqn0biw043no"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "(data.feature_names, \n",
        "data.target_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UewLJf81BZW"
      },
      "source": [
        "## Interactive Visualization of Decision Tree Classifers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm4tCSBpXPze"
      },
      "source": [
        "!pip install ipywidgets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bgj72xZqy1kS"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn import tree\n",
        "from sklearn.datasets import load_iris, load_breast_cancer\n",
        "from IPython.display import SVG\n",
        "from graphviz import Source\n",
        "from IPython.display import display                               \n",
        "from ipywidgets import interactive\n",
        "# load dataset\n",
        "data = load_iris() #load_iris()\n",
        "# feature matrix\n",
        "X = data.data\n",
        "# target vector\n",
        "y = data.target\n",
        "# class labels\n",
        "labels = data.feature_names\n",
        "def plot_tree(crit, split, depth, min_split, min_leaf=0.2):\n",
        "  estimator = DecisionTreeClassifier(random_state = 0, criterion = crit, \n",
        "                                     splitter = split, max_depth = depth,\n",
        "                                     min_samples_split=min_split, \n",
        "                                     min_samples_leaf=min_leaf)\n",
        "  estimator.fit(X, y)\n",
        "  graph = Source(tree.export_graphviz(estimator, out_file=None, \n",
        "                                      feature_names=labels, \n",
        "                                      class_names=['0', '1', '2'], filled = True))\n",
        "  display(SVG(graph.pipe(format='svg')))\n",
        "  return estimator\n",
        "\n",
        "inter=interactive(plot_tree, \n",
        "                  crit = [\"gini\", \"entropy\"] , \n",
        "                  split = [\"best\", \"random\"] , \n",
        "                  depth=[1,2,3,4], \n",
        "                  min_split=(0.1,1), #min number of samples to further split a node\n",
        "                  min_leaf=(0.1,0.5)) #min number of samples required to be a leaf node\n",
        "display(inter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ufuqXZu2_PL"
      },
      "source": [
        "Outcome classes for visualized Decision Tree (Breast Cancer dataset)\n",
        "*   Benign=1\n",
        "*   Malignant=0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaKmWxM5YEp9"
      },
      "source": [
        "### Question 8\r\n",
        "What is most important variable to consider when classifying tumors according to the Decision Tree we have built?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BJ_AL5k3dE_"
      },
      "source": [
        "Outcome classes for visualized Decision Tree (Iris dataset)\n",
        "*   Iris Setosa = 0\n",
        "*   Iris Versicolour = 1\n",
        "*   Iris Virginica = 2\n",
        "\n",
        "### Question 9\n",
        "What is the most important variable to consider when classifying Iris plants?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPOnI6iyYOAb"
      },
      "source": [
        "answer"
      ]
    }
  ]
}