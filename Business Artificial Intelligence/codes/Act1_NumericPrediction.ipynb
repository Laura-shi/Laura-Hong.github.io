{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_NumericPrediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilDZejkWbYQH"
      },
      "source": [
        "# Supervised Learning \r\n",
        "In Machine Learning, Supervised learning is the task of learning a function that maps an input to an output based on sample input-output pairs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWLMBCgxUMfj"
      },
      "source": [
        "One of its applications is to predict numeric outcomes; we train an alogorithm to learn how to map input(s) to a numeric outcome value. \n",
        "\n",
        "# Numeric Prediction\n",
        "In this activity We will become familiar with several models for **predicting numeric outcomes**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJN4ToHIUCtr"
      },
      "source": [
        "# make sure to upload the dataset to your colab folder before proceeding (see instructions in 1_GettingStarted)\n",
        "#loading the 50_startups datasets as a panda dataframe\n",
        "import pandas as pd\n",
        "dataset = pd.read_csv('50_Startups.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-wX6li38YNu"
      },
      "source": [
        "# if you are using the file from your google drive \r\n",
        "import pandas as pd\r\n",
        "from google.colab import drive\r\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/MIS7720/50_Startups.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DJRHcK0m8Iw"
      },
      "source": [
        "#take a look a descriptive statistics \r\n",
        "dataset.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omXJXwfugd6p"
      },
      "source": [
        "## Visually exploring our dataset\r\n",
        "We will use the seaborn library to create some visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrSkfXsmciNl"
      },
      "source": [
        "#visually exploring the dataset \n",
        "#the next few cells demonstrate several graphs that can be useful to visually explore your data\n",
        "import seaborn as sb\n",
        "sb.distplot(dataset['R&D Spend']) #histogram for R&D spending"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb2feJmycuzW"
      },
      "source": [
        "sb.distplot(dataset['Administration']) #histogram for Administration spending\n",
        "sb.distplot(dataset['Marketing Spend'])  #histogram for Marketing spending"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM7XzBSBdha3"
      },
      "source": [
        "#comparing R&D spending across states using violin plots\n",
        "sb.violinplot(x=\"State\",y=\"R&D Spend\", data=dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWvn_hPzdkbP"
      },
      "source": [
        "#comparing R&D spending across states using box\n",
        "sb.boxplot(x=\"State\",y=\"R&D Spend\", data=dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ingYyWKMgrE7"
      },
      "source": [
        "#scatter plot of Profits vs. Marketing Spending, colored by State\n",
        "sb.scatterplot(x=\"Marketing Spend\",y=\"Profit\",hue=\"State\", data=dataset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4Me5Zcthfrk"
      },
      "source": [
        "dataset.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGaC-tHLguiE"
      },
      "source": [
        "##preparing the data for model training\n",
        "#dataset.iloc[0,3] #points to a specific [row,column] ; index starts at 0\n",
        "#defining input and outcome variables\n",
        "y = dataset[['Profit']]  #profit\n",
        "#X = dataset.drop(labels=['Profit','State'], axis=1) #other variables\n",
        "X = dataset.drop('Profit',axis=1) #other variables"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDtmn2pFhb1e"
      },
      "source": [
        "#before encoding the State variable\n",
        "X.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YugY2jGSg2QU"
      },
      "source": [
        "#The state variable is categorical, \n",
        "#we use binary encoding to create binary variable for each level of the State variable\n",
        "pd.get_dummies(X['State']).head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXChaER2rzDC"
      },
      "source": [
        "#add the binary encoded State variables to our X variable\n",
        "X=pd.concat([X,pd.get_dummies(X['State'])],axis=1) \n",
        "# drop the State column, since we now have the binary encoded vars\n",
        "X.drop(['State'],axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSRqUSgq0anB"
      },
      "source": [
        "#after encoding the State variable\n",
        "X.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjuGxQnHjWPt"
      },
      "source": [
        "## Splitting the data into Train and Test sets\r\n",
        "\r\n",
        "We split the dataset: keep 20% for testing and the rest for training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kHStDLBh-Pc"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)  #using same random_state value for replicability\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dqeUwaXj1Ds"
      },
      "source": [
        "###**Question1 :**\r\n",
        "Do we have to use 20% for the testing? would you use a 40% test set for this dataset? why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz-6aO6tkB7m"
      },
      "source": [
        "answer here "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y00n3axvMjdz"
      },
      "source": [
        "# let's take another look at the resulting datasets after splitting\r\n",
        "X_train.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvmTY-pug5DN"
      },
      "source": [
        "## Linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnmCsAtR0kZq"
      },
      "source": [
        "#### Fitting Multiple Linear Regression to the Training set  ####\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6v6vlWJ0woC"
      },
      "source": [
        "# Predicting the Test set results\n",
        "y_pred_lin = lin_reg.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4yAs6xuguZ9"
      },
      "source": [
        "importing model evaluation metrics from sklearn "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8FwgPMJ042j"
      },
      "source": [
        "from sklearn import metrics\n",
        "import math\n",
        "# The coefficients\n",
        "print('Coefficients: \\n', lin_reg.coef_)\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % metrics.mean_squared_error(Y_test, y_pred_lin))\n",
        "print(\"Root Mean squared error: %.2f\" % math.sqrt(metrics.mean_squared_error(Y_test, y_pred_lin)))\n",
        "# The mean absolute error\n",
        "print(\"Mean absolute error: %.2f\" % metrics.mean_absolute_error(Y_test, y_pred_lin))\n",
        "# R-square: 1 is perfect prediction\n",
        "print('R-square: %.2f' % metrics.r2_score(Y_test, y_pred_lin))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfCsFHiSkXGO"
      },
      "source": [
        "### Using the trained model to predict Profit for a new input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuJDx6qI3KEt"
      },
      "source": [
        "#X_new=pd.read_csv('50_Startups_newinput.csv')\n",
        "#print(X_new)\n",
        "#lin_reg.predict(X_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYmDM7WMhC1F"
      },
      "source": [
        "## Decision Tree Regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy3ZyrWz141d"
      },
      "source": [
        "#### Fitting Decision Tree Regression to the dataset  ###########\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "DecTree_reg = DecisionTreeRegressor(random_state = 123)\n",
        "DecTree_reg.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcHqI-Zf2Fxj"
      },
      "source": [
        "# evaluating Decision Tree Regression\n",
        "y_pred_DT = DecTree_reg.predict(X_test)\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % metrics.mean_squared_error(Y_test, y_pred_DT))\n",
        "print(\"Root Mean squared error: %.2f\" % math.sqrt(metrics.mean_squared_error(Y_test, y_pred_DT)))\n",
        "print(\"Mean absolute error: %.2f\" % metrics.mean_absolute_error(Y_test, y_pred_DT))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8-aWRx2hIr6"
      },
      "source": [
        "## Random Forest Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja4p6W1y2Kh8"
      },
      "source": [
        "#### Fitting Random Forest Regression to the dataset ##########\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "RandForest_reg = RandomForestRegressor(n_estimators = 10, min_samples_leaf=1, random_state = 0)\n",
        "RandForest_reg.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_r_jHHG2Lo8"
      },
      "source": [
        "#evaluting RandForest_reg\n",
        "y_pred_RF = RandForest_reg.predict(X_test)\n",
        "print(\"Mean squared error: %.2f\" % metrics.mean_squared_error(Y_test, y_pred_RF))\n",
        "print(\"Root Mean squared error: %.2f\" % math.sqrt(metrics.mean_squared_error(Y_test, y_pred_RF)))\n",
        "print(\"Mean absolute error: %.2f\" % metrics.mean_absolute_error(Y_test, y_pred_RF))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ01eSu-hMgI"
      },
      "source": [
        "## Support Vector Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5hLQleF2TfU"
      },
      "source": [
        "#########  Support Vector Regression #########\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler,minmax_scale\n",
        "sc_X = StandardScaler() \n",
        "sc_y = StandardScaler()\n",
        "X_train_sc = sc_X.fit_transform(X_train)\n",
        "y_train_sc = sc_y.fit_transform(Y_train) #.reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-26CxZH21md"
      },
      "source": [
        "# Fitting SVR to the dataset\n",
        "from sklearn.svm import SVR\n",
        "svr_reg = SVR(kernel = 'rbf')\n",
        "svr_reg.fit(X_train_sc, y_train_sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwAdfyaR26Rd"
      },
      "source": [
        "# evaluating SVR regresion\n",
        "y_pred = svr_reg.predict(sc_X.fit_transform(X_test))\n",
        "y_pred_SVC = sc_y.inverse_transform(y_pred) #inverse applying the scaler\n",
        "\n",
        "print(\"Mean squared error: %.2f\" % metrics.mean_squared_error(Y_test, y_pred_SVC))\n",
        "print(\"Root Mean squared error: %.2f\" % math.sqrt(metrics.mean_squared_error(Y_test, y_pred_SVC)))\n",
        "print(\"Mean absolute error: %.2f\" % metrics.mean_absolute_error(Y_test, y_pred_SVC))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxplfuIXkwpv"
      },
      "source": [
        "##Comparing Different models\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAR8rySBstdH"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "names = ['Linear Reg','DT Reg','RF reg','SVR']\r\n",
        "predictions=[y_pred_lin,y_pred_DT,y_pred_RF,y_pred_SVC]\r\n",
        "results = []\r\n",
        "\r\n",
        "for y_pred in predictions:\r\n",
        "  rmse=round(math.sqrt(metrics.mean_squared_error(Y_test, y_pred)),2)\r\n",
        "  #mae=round(metrics.mean_absolute_error(Y_test, y_pred),2)\r\n",
        "  results.append(rmse) #change rmse to mae \r\n",
        "  \r\n",
        "# create a bar plot to compare values\r\n",
        "fig = plt.figure()\r\n",
        "fig.suptitle('Model RMSE Comparison: ')\r\n",
        "ax = fig.add_subplot(111)\r\n",
        "plt.bar(names,results)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1tUz4bFlt3Y"
      },
      "source": [
        "###Question 2\r\n",
        "Which model would have a better predictive performance? you can run the next cell to see the RMSE values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMcMaXNv9KrI"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CugKwaBbmKcc"
      },
      "source": [
        "answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwBR_B-dmNTM"
      },
      "source": [
        "###Question 3\r\n",
        "Use Mean Absolute error (MAE) in the previous code cell as model evluation metric (see video instructions). Which model has a better performance in terms of MAE? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_UtbDLUmyHt"
      },
      "source": [
        "answer here"
      ]
    }
  ]
}