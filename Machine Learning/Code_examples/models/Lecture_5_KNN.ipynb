{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN method from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required modules\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    " \n",
    "#Euclidean Distance\n",
    "def eucledian(p1,p2):\n",
    "    dist = np.sqrt(np.sum((p1-p2)**2))\n",
    "    return dist\n",
    " \n",
    "#Function to calculate KNN\n",
    "def predict_KNN(x_train, y , x_input, k):\n",
    "    op_labels = []\n",
    "     \n",
    "    #Loop through the Datapoints to be classified\n",
    "    for item in x_input: \n",
    "         \n",
    "        #Array to store distances\n",
    "        point_dist = []\n",
    "         \n",
    "        #Loop through each training Data\n",
    "        for j in range(len(x_train)): \n",
    "            distances = eucledian(np.array(x_train[j,:]) , item) \n",
    "            #Calculating the distance\n",
    "            point_dist.append(distances) \n",
    "        point_dist = np.array(point_dist) \n",
    "         \n",
    "        #Sorting the array while preserving the index\n",
    "        #Keeping the first K datapoints\n",
    "        dist = np.argsort(point_dist)[:k] \n",
    "         \n",
    "        #Labels of the K datapoints from above\n",
    "        labels = y[dist]\n",
    "        #print(labels)\n",
    "        \n",
    "        #Majority voting\n",
    "        lab = mode(labels) \n",
    "        lab = lab.mode[0]\n",
    "        op_labels.append(lab)\n",
    "        \n",
    "    return op_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "[0 0 0 0 0]\n",
      "Testing accuracy is :  1.0\n",
      "EVALUATION ON TESTING DATA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        50\n",
      "   macro avg       1.00      1.00      1.00        50\n",
      "weighted avg       1.00      1.00      1.00        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-4387d8adec1e>:36: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  lab = mode(labels)\n"
     ]
    }
   ],
   "source": [
    "#Importing the required modules\n",
    "#Importing required modules\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from numpy.random import randint\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#Loading the Data\n",
    "iris= load_iris()\n",
    " \n",
    "# Store features matrix in X\n",
    "X= iris.data\n",
    "#Store target vector in \n",
    "y= iris.target\n",
    " \n",
    "print(X[:5])\n",
    "print(y[:5])\n",
    "#Creating the training Data\n",
    "train_idx = randint(0,150,100)\n",
    "X_train = X[train_idx]\n",
    "y_train = y[train_idx]\n",
    " \n",
    "#Creating the testing Data\n",
    "test_idx = randint(0,150,50) #taking 50 random samples\n",
    "X_test = X[test_idx]\n",
    "y_test = y[test_idx]\n",
    " \n",
    "#Applying our function \n",
    "y_pred = predict_KNN(X_train,y_train,X_test , 7)\n",
    "\n",
    "#print(y_pred)\n",
    "\n",
    "#Checking the accuracy\n",
    "testing_acc = accuracy_score(y_test, y_pred)\n",
    "print('Testing accuracy is : ', testing_acc)\n",
    "\n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN method using Sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data points: 1212\n",
      "validation data points: 135\n",
      "testing data points: 450\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from __future__ import print_function\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import datasets\n",
    "from skimage import exposure\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sklearn\n",
    "\n",
    "# handle older versions of sklearn\n",
    "if int((sklearn.__version__).split(\".\")[1]) < 18:\n",
    "\tfrom sklearn.cross_validation import train_test_split\n",
    "\n",
    "# otherwise we're using at lease version 0.18\n",
    "else:\n",
    "\tfrom sklearn.model_selection import train_test_split\n",
    "\n",
    "# load the MNIST digits dataset\n",
    "mnist = datasets.load_digits()\n",
    "\n",
    "# take the MNIST data and construct the training and testing split, using 75% of the\n",
    "# data for training and 25% for testing\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(np.array(mnist.data),\n",
    "\tmnist.target, test_size=0.25, random_state=42)\n",
    "\n",
    "# now, let's take 10% of the training data and use that for validation\n",
    "(trainData, valData, trainLabels, valLabels) = train_test_split(trainData, trainLabels,\n",
    "\ttest_size=0.1, random_state=84)\n",
    "\n",
    "# show the sizes of each data split\n",
    "print(\"training data points: {}\".format(len(trainLabels)))\n",
    "print(\"validation data points: {}\".format(len(valLabels)))\n",
    "print(\"testing data points: {}\".format(len(testLabels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data splits taken care of, letâ€™s train our classifier and find the optimal value of k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, accuracy=99.26%\n",
      "k=3, accuracy=99.26%\n",
      "k=5, accuracy=99.26%\n",
      "k=7, accuracy=99.26%\n",
      "k=9, accuracy=99.26%\n",
      "k=11, accuracy=99.26%\n",
      "k=13, accuracy=99.26%\n",
      "k=15, accuracy=99.26%\n",
      "k=17, accuracy=98.52%\n",
      "k=19, accuracy=98.52%\n",
      "k=21, accuracy=97.78%\n",
      "k=23, accuracy=97.04%\n",
      "k=25, accuracy=97.78%\n",
      "k=27, accuracy=97.04%\n",
      "k=29, accuracy=97.04%\n",
      "k=1 achieved highest accuracy of 99.26% on validation data\n"
     ]
    }
   ],
   "source": [
    "# initialize the values of k for our k-Nearest Neighbor classifier along with the\n",
    "# list of accuracies for each value of k\n",
    "kVals = range(1, 30, 2)\n",
    "accuracies = []\n",
    "\n",
    "# loop over various values of `k` for the k-Nearest Neighbor classifier\n",
    "for k in range(1, 30, 2):\n",
    "\t# train the k-Nearest Neighbor classifier with the current value of `k`\n",
    "\tmodel = KNeighborsClassifier(n_neighbors=k)\n",
    "\tmodel.fit(trainData, trainLabels)\n",
    "\n",
    "\t# evaluate the model and update the accuracies list\n",
    "\tscore = model.score(valData, valLabels)\n",
    "\tprint(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n",
    "\taccuracies.append(score)\n",
    "\n",
    "# find the value of k that has the largest accuracy\n",
    "i = int(np.argmax(accuracies))\n",
    "print(\"k=%d achieved highest accuracy of %.2f%% on validation data\" % (kVals[i],\n",
    "\taccuracies[i] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the values of k=1 to k=15 all obtained the same accuracy. However, computing the distance to only a single neighbor is substantially more efficient, thus we will use k=1 to train and evaluate our classifier on the final testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION ON TESTING DATA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.97        37\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       0.98      0.98      0.98        46\n",
      "           4       0.98      0.98      0.98        55\n",
      "           5       0.98      1.00      0.99        59\n",
      "           6       1.00      1.00      1.00        45\n",
      "           7       1.00      0.98      0.99        41\n",
      "           8       0.97      0.95      0.96        38\n",
      "           9       0.96      0.94      0.95        48\n",
      "\n",
      "    accuracy                           0.98       450\n",
      "   macro avg       0.98      0.98      0.98       450\n",
      "weighted avg       0.98      0.98      0.98       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# re-train our classifier using the best k value and predict the labels of the\n",
    "# test data\n",
    "model = KNeighborsClassifier(n_neighbors=kVals[0])\n",
    "model.fit(trainData, trainLabels)\n",
    "predictions = model.predict(testData)\n",
    "\n",
    "# show a final classification report demonstrating the accuracy of the classifier\n",
    "# for each of the digits\n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(testLabels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, 98% accuracy! Thatâ€™s quite high! Furthermore, we can see the digits 0, 2, 6, and 7 are classified correctly 100% of the time. The digit 1 obtains the lowest classification accuracy of 95%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Performance matrics...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import the necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "#Create the NumPy array for actual and predicted labels.\n",
    "actual    = np.array(\n",
    "  ['Dog','Dog','Dog','Not Dog','Dog','Not Dog','Dog','Dog','Not Dog','Not Dog'])\n",
    "predicted = np.array(\n",
    "  ['Dog','Not Dog','Dog','Not Dog','Dog','Dog','Dog','Dog','Not Dog','Not Dog'])\n",
    " \n",
    "#compute the confusion matrix.\n",
    "cm = confusion_matrix(actual,predicted)\n",
    " \n",
    "#Plot the confusion matrix.\n",
    "sns.heatmap(cm,\n",
    "            annot=True,\n",
    "            fmt='g',\n",
    "            xticklabels=['Dog','Not Dog'],\n",
    "            yticklabels=['Dog','Not Dog'])\n",
    "plt.ylabel('Prediction',fontsize=13)\n",
    "plt.xlabel('Actual',fontsize=13)\n",
    "plt.title('Confusion Matrix',fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy   : 0.8\n",
      "Precision : 0.8333333333333334\n",
      "Recall    : 0.8333333333333334\n",
      "F1-score  : 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Finding precision and recall\n",
    "accuracy = (cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
    "print(\"Accuracy   :\", accuracy)\n",
    "precision = (cm[0,0])/(cm[0,0]+cm[0,1])\n",
    "print(\"Precision :\", precision)\n",
    "recall = (cm[0,0])/(cm[0,0]+cm[1,0])\n",
    "print(\"Recall    :\", recall)\n",
    "F1_score = 2*((precision*recall)/(precision+recall)) \n",
    "print(\"F1-score  :\", F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
