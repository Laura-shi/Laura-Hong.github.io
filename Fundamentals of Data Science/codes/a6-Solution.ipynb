{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5074219-7448-4bc3-b680-63c7e7315f39",
   "metadata": {},
   "source": [
    "# COMP 7150 Assignment 6 SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36b0732-eadd-421f-9181-547e8570e7f1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**How each problem is graded**\n",
    "\n",
    "This is a general guideline.  There might be some variant for a specific problem.\n",
    "\n",
    "* Answering the question in English: 25%\n",
    "    + Thorough answering the question, explaning the findings, discussing the comparison: 10-25%\n",
    "    + Not answering the question in English: 0%.\n",
    "    + Note: An answer is written in English to address a specific question. The answer must come first.  \n",
    "* Code: 50%\n",
    "    + Code is correct: 50%\n",
    "    + Code is correct, but missing some minor elements: 25-40%\n",
    "    + Incorrect solution, but make an effort: 10%-25%\n",
    "    + Empty: 0% \n",
    "    + Note: code is not an answer. Code shows how you get an answer.  Code comes after an answer.\n",
    "* Explanation of code: 10%\n",
    "    + Concise English explanation of solution/code: 10%\n",
    "    + No explanation: 0%\n",
    "* Testing: 15%\n",
    "    + Providing adequate testing of code: 15%\n",
    "    + Code operational but does not show how the answer(s) were generated: 5%\n",
    "    + Code not runnable or no testing: 0%\n",
    "\n",
    "\n",
    "**How to turn in your assignment**\n",
    "\n",
    "+ Export your notebook to an HTML file.\n",
    "+ Upload it to the appropriate folder in Assignments on Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7db3e6a-d75f-4737-8cb6-bfc753e07c09",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "\n",
    "The dataset you'll used for this assignment is diabetes.csv\n",
    "\n",
    "The target variable is Outcome. The other 8 variables are features.\n",
    "\n",
    "Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "* Pregnancies: Number of times pregnant\n",
    "* Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "* BloodPressure: Diastolic blood pressure (mm Hg)\n",
    "* SkinThickness: Triceps skin fold thickness (mm)\n",
    "* Insulin: 2-Hour serum insulin (mu U/ml)\n",
    "* BMI: Body mass index (weight in kg/(height in m)^2)\n",
    "* DiabetesPedigreeFunction: Diabetes pedigree function\n",
    "* Age: Age (years)\n",
    "* Outcome: Class variable (0 or 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8bbe85-47ce-49b4-a66b-faa6be7cd0f3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Each problem is worth 20 points.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e57682ed-20c2-4a2b-8039-a89904ee68a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ddb4251-6177-4df6-88d3-c3ed8d185391",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 1**\n",
    "\n",
    "Some of the features have missing values.  Unfortunately, in this dataset, missing values are not indicated as \"nan\".  Therefore, if you use pandas' \"dropna\", it won't work.\n",
    "\n",
    "However, if you understand the meanings of the features, you can guess which ones have missing values.  For example, blood pressure should not be less than 20.\n",
    "\n",
    "Find the features that you think have missing values in the dataset.  For each feature, explain why you think they have missing values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243ec547-d20a-4a7a-af31-fa96c29c776b",
   "metadata": {},
   "source": [
    "ANSWER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22f95d93-a8b4-418a-9601-5558c422e5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>4</td>\n",
       "      <td>137</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0.252</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "351            4      137             84              0        0  31.2   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "351                     0.252   30        0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "diabetes = pandas.read_csv('../Datasets/diabetes.csv')\n",
    "diabetes.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f1dfa6-3366-43c8-bcc9-6097d68b7e31",
   "metadata": {},
   "source": [
    "Certain features (Glucose, BloodPressure, SkinThickness, Insulin, BMI, Age) should not have 0 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb76dc15-7bac-41ed-b5c1-77d16ef7521b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set size: 768\n",
      "Valid data for BloodPressure 733\n",
      "Valid data for Glucose 763\n",
      "Valid data for BMI 757\n",
      "Valid data for Insulin 394\n",
      "Valid data for SkinThickness 541\n",
      "\n",
      "Valid data: 392\n"
     ]
    }
   ],
   "source": [
    "valid_bloodpressure = diabetes['BloodPressure'] > 0\n",
    "valid_glucose = diabetes['Glucose'] > 0\n",
    "valid_bmi = diabetes['BMI'] > 0\n",
    "valid_insulin = diabetes['Insulin'] > 0\n",
    "valid_skin = diabetes['SkinThickness'] > 0\n",
    "valid_age = diabetes['Age'] > 0\n",
    "\n",
    "\n",
    "print('Data set size:', len(diabetes))\n",
    "print('Valid data for BloodPressure', len(diabetes[valid_bloodpressure]))\n",
    "print('Valid data for Glucose', len(diabetes[valid_glucose]))\n",
    "print('Valid data for BMI', len(diabetes[valid_bmi]))\n",
    "print('Valid data for Insulin', len(diabetes[valid_insulin]))\n",
    "print('Valid data for SkinThickness', len(diabetes[valid_skin]))\n",
    "print()\n",
    "Q = valid_bloodpressure & valid_glucose & valid_bmi & valid_insulin & valid_skin & valid_age\n",
    "print('Valid data:', len(diabetes[Q]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0eaa39-2097-4ec9-9978-1facf9483f1d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 2**\n",
    "\n",
    "Remove the missing values from the diabetes dataset.\n",
    "\n",
    "Find 3 decision models with the best F1 scores, based on these characteristics:\n",
    "* The first model: find the best max_depth.\n",
    "* The second model: find the best min_samples_leaf\n",
    "* The third model: find the best combination of max_depth and min_samples_leaf\n",
    "\n",
    "Evaluate your models using f1_score and ShuffleSplit with 100 splits.\n",
    "\n",
    "You can read about these two parameters here: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257f2346-1cb6-45b0-a8a2-9c134027a3a4",
   "metadata": {},
   "source": [
    "ANSWER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db0c67e9-f723-4eaf-9a20-676be98d0750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid data: 392 0.5104166666666666\n"
     ]
    }
   ],
   "source": [
    "valid_bloodpressure = diabetes['BloodPressure'] > 0\n",
    "valid_glucose = diabetes['Glucose'] > 0\n",
    "valid_bmi = diabetes['BMI'] > 0\n",
    "valid_insulin = diabetes['Insulin'] > 0\n",
    "valid_skin = diabetes['SkinThickness'] > 0\n",
    "valid_age = diabetes['Age'] > 0\n",
    "\n",
    "Q = valid_bloodpressure & valid_glucose & valid_bmi & valid_insulin & valid_skin & valid_age\n",
    "\n",
    "data = diabetes[Q]\n",
    "\n",
    "print('Valid data:', len(data), len(data)/len(diabetes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cd9184-eb9a-4290-8939-46c02c6bb5d6",
   "metadata": {},
   "source": [
    "We lose about 50% of the data after removing missing values.\n",
    "\n",
    "There are ways of guesstimating missing values, but we won't be discuss them here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddf3372-356c-4a88-a193-257f132b0053",
   "metadata": {},
   "source": [
    "**Finding the best max_depth for a decision tree model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53948dfd-160c-4ea7-9d24-707fc1dbfa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.52\n",
      "3 0.68\n",
      "4 0.63\n",
      "5 0.62\n",
      "6 0.59\n",
      "7 0.58\n",
      "8 0.58\n",
      "10 0.56\n",
      "14 0.57\n",
      "16 0.58\n",
      "18 0.58\n",
      "20 0.58\n",
      "22 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate, ShuffleSplit\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X, y = data.drop(columns=['Outcome']), data['Outcome']\n",
    "cv = ShuffleSplit(n_splits=100)\n",
    "\n",
    "for d in [2, 3, 4, 5, 6, 7, 8, 10, 14, 16, 18, 20, 22]:\n",
    "    dt = DecisionTreeClassifier(max_depth=d)\n",
    "    r = cross_validate(dt, X, y, cv=cv, scoring='f1')\n",
    "    print(d, r['test_score'].mean().round(2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e21ba4ce-b2ae-4083-897c-5e5080d65a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best max_depth seems to be 3.\n",
    "model1 = DecisionTreeClassifier(max_depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a65d53d-333e-49d4-9868-902c0d9810b6",
   "metadata": {},
   "source": [
    "**Finding the best min_samples_leaf for a decision tree model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56a878e0-4e98-4012-beff-31380ecc6298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.57\n",
      "3 0.62\n",
      "4 0.61\n",
      "5 0.61\n",
      "6 0.6\n",
      "7 0.6\n",
      "8 0.62\n",
      "9 0.63\n",
      "10 0.61\n",
      "11 0.62\n",
      "12 0.61\n",
      "13 0.62\n",
      "14 0.62\n",
      "15 0.61\n",
      "16 0.62\n",
      "17 0.62\n",
      "18 0.6\n",
      "19 0.57\n",
      "20 0.58\n",
      "21 0.59\n",
      "22 0.62\n",
      "23 0.6\n",
      "24 0.61\n"
     ]
    }
   ],
   "source": [
    "X, y = data.drop(columns=['Outcome']), data['Outcome']\n",
    "cv = ShuffleSplit(n_splits=100)\n",
    "\n",
    "for d in range(2,25):\n",
    "    dt = DecisionTreeClassifier(min_samples_leaf=d)\n",
    "    r = cross_validate(dt, X, y, cv=cv, scoring='f1')\n",
    "    print(d, r['test_score'].mean().round(2))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a73e828-4d20-4048-8b28-27e1718753b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are multiple values\n",
    "model2 = DecisionTreeClassifier(min_samples_leaf=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6c2367-6501-4b70-be66-374741e72e81",
   "metadata": {},
   "source": [
    "#### Identifying the best combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45560805-bb12-46df-ba2a-f27ad40dc1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 5 0.61\n",
      "2 6 0.61\n",
      "2 7 0.58\n",
      "2 8 0.6\n",
      "2 9 0.55\n",
      "2 10 0.57\n",
      "2 11 0.58\n",
      "2 12 0.58\n",
      "2 13 0.58\n",
      "2 14 0.58\n",
      "3 5 0.63\n",
      "3 6 0.6\n",
      "3 7 0.6\n",
      "3 8 0.59\n",
      "3 9 0.59\n",
      "3 10 0.58\n",
      "3 11 0.57\n",
      "3 12 0.6\n",
      "3 13 0.58\n",
      "3 14 0.58\n",
      "4 5 0.62\n",
      "4 6 0.61\n",
      "4 7 0.61\n",
      "4 8 0.62\n",
      "4 9 0.62\n",
      "4 10 0.59\n",
      "4 11 0.6\n",
      "4 12 0.6\n",
      "4 13 0.6\n",
      "4 14 0.6\n",
      "5 5 0.63\n",
      "5 6 0.58\n",
      "5 7 0.62\n",
      "5 8 0.62\n",
      "5 9 0.61\n",
      "5 10 0.63\n",
      "5 11 0.63\n",
      "5 12 0.63\n",
      "5 13 0.62\n",
      "5 14 0.61\n",
      "6 5 0.61\n",
      "6 6 0.6\n",
      "6 7 0.61\n",
      "6 8 0.6\n",
      "6 9 0.64\n",
      "6 10 0.61\n",
      "6 11 0.61\n",
      "6 12 0.58\n",
      "6 13 0.62\n",
      "6 14 0.6\n"
     ]
    }
   ],
   "source": [
    "cv = ShuffleSplit(n_splits=100)\n",
    "        \n",
    "for l in range(2,7):\n",
    "    for d in range(5,15):\n",
    "        dt = DecisionTreeClassifier(max_depth=d, min_samples_leaf=l)\n",
    "        r = cross_validate(dt, X, y, cv=cv, scoring='f1')\n",
    "        print(l, d, r['test_score'].mean().round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "578e6b7e-485f-41d3-8632-043165571097",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = DecisionTreeClassifier(min_samples_leaf=6, max_depth=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6787cd1a-2f64-43b3-abf5-ca00bdce93fc",
   "metadata": {},
   "source": [
    "---\n",
    "**Problem 3**\n",
    "\n",
    "Compare the performance of the best decision tree classifier and a random forest (with similar max_depth and min_samples_leaf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c959320-1aa6-40d0-8721-51ef7a1eb56c",
   "metadata": {},
   "source": [
    "ANSWER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "381c572c-6863-4354-a7cc-cc7c18649eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, ShuffleSplit, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X, y = data.drop(columns=['Outcome']), data['Outcome']\n",
    "cv = ShuffleSplit(n_splits=100)\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=6, max_depth=9)\n",
    "rf = RandomForestClassifier(min_samples_leaf=6, max_depth=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f0533b2-60f4-45d5-b620-2bd4912380e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.63\n"
     ]
    }
   ],
   "source": [
    "cv = ShuffleSplit(n_splits=100)\n",
    "result_dt = cross_validate(dt, X, y, cv=cv, scoring='f1')\n",
    "result_rf = cross_validate(rf, X, y, cv=cv, scoring='f1')\n",
    "\n",
    "print(result_dt['test_score'].mean().round(2))\n",
    "print(result_rf['test_score'].mean().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f6e4344d-97ce-40ed-a0d6-91c8df69b1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63\n",
      "0.67\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "result_dt = cross_validate(dt, X, y, cv=cv, scoring='f1')\n",
    "result_rf = cross_validate(rf, X, y, cv=cv, scoring='f1')\n",
    "\n",
    "print(result_dt['test_score'].mean().round(2))\n",
    "print(result_rf['test_score'].mean().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0945ec4a-0520-4e24-a3b7-7feb9e8dd3c7",
   "metadata": {},
   "source": [
    "The result depends on a specific cross validator. Overall, random forest seems to perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba999864-fd9e-4d3f-97ab-2f3768dd281b",
   "metadata": {},
   "source": [
    "---\n",
    "**Problem 4**\n",
    "\n",
    "By default, a random forest classifier uses 100 random trees (n_estimators). The larger the number of random trees, the longer it takes to train and predict.\n",
    "\n",
    "What is the smallest number random trees in a random forest do you need for a random forest classifer to outperform your best decision tree classifier?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef542bcb-9534-42ba-b40c-a2c084a4f345",
   "metadata": {},
   "source": [
    "ANSWER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a20f5f4-ecc5-4bc3-9506-187b326a8fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.63\n",
      "20 0.65\n",
      "30 0.63\n",
      "40 0.64\n",
      "50 0.63\n",
      "60 0.66\n",
      "70 0.62\n",
      "80 0.63\n",
      "90 0.65\n",
      "100 0.65\n",
      "110 0.64\n",
      "120 0.65\n",
      "130 0.64\n",
      "140 0.66\n",
      "150 0.66\n",
      "160 0.65\n",
      "170 0.65\n",
      "180 0.62\n",
      "190 0.62\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "for n in range(10,200,10):\n",
    "    model = RandomForestClassifier(n_estimators=n, min_samples_leaf=6, max_depth=9)\n",
    "    result_rf = cross_validate(rf, X, y, cv=cv, scoring='f1')\n",
    "    print(n, result_rf['test_score'].mean().round(2))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828089b7-83fc-47d4-b3d2-51a641826c2a",
   "metadata": {},
   "source": [
    "With 10-Fold cv, n ~ 60 gives good results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c174e3-8820-4990-9f0e-2d705af14dc8",
   "metadata": {},
   "source": [
    "---\n",
    "**Problem 5**\n",
    "\n",
    "Compare the performance of the best decision tree classifier and logistic regression classifier.\n",
    "\n",
    "If your logistic regression classifer doesn't convert, you can increase max_iter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956253b9-5167-4edd-948a-bb65d7abbd63",
   "metadata": {},
   "source": [
    "ANSWER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f18e356-6024-4c8d-89ac-36d031898369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, ShuffleSplit, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X, y = data.drop(columns=['Outcome']), data['Outcome']\n",
    "cv = ShuffleSplit(n_splits=100)\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=6, max_depth=9)\n",
    "logit = LogisticRegression(max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2426127d-2541-4a25-ba55-d594a9326ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61\n",
      "0.63\n"
     ]
    }
   ],
   "source": [
    "cv = ShuffleSplit(n_splits=100)\n",
    "result_dt = cross_validate(dt, X, y, cv=cv, scoring='f1')\n",
    "result_logit = cross_validate(logit, X, y, cv=cv, scoring='f1')\n",
    "\n",
    "print(result_dt['test_score'].mean().round(2))\n",
    "print(result_logit['test_score'].mean().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f68175ac-d04c-419c-907c-4d10c7c995a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63\n",
      "0.64\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10)\n",
    "result_dt = cross_validate(dt, X, y, cv=cv, scoring='f1')\n",
    "result_logit = cross_validate(logit, X, y, cv=cv, scoring='f1')\n",
    "\n",
    "print(result_dt['test_score'].mean().round(2))\n",
    "print(result_logit['test_score'].mean().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7082102-3080-468e-881b-14c2c4fc1ca2",
   "metadata": {},
   "source": [
    "Logistic regression is to be slightly better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
